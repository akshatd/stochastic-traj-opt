\documentclass{article}
\usepackage[a4paper, total={7in, 8in}]{geometry}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath} % Required for some math elements
\usepackage{hyperref} % Required for hyperlinks
\usepackage{amssymb} % Required for probability symbols
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{MultifidelityTrajectoryOptimization}
\author{goroda }
\date{October 2024}

\begin{document}

\maketitle

\begin{abstract}
  TODO: abstract
\end{abstract}

\section{Introduction}
TODO: introduction
\section{Background}
TODO: background

\section{Problem Formulation}
In this paper, we propose a multifidelity approach to stochastic trajectory optimization with sample average approximation.
The objective is to minimize the expected value of the objective function, which is chosen an an LQR controller for a mass-spring-damper system.
A mass-spring-damper system is considered for ease of modelling, since the focus is on the multifidelity approach
and not on the complexity of the system dynamics.
The LQR controller attempts to find the optimal trajectory for tracking a reference position and velocity of the mass-spring-damper system.
This section describes how the dynamics for the mass-spring-damper is set up, along with the controller design and objective function for the trajectory optimization problem.

\subsection{Mass-Spring-Damper System}
The mass-spring-damper system is a second order system that can be modelled using Newton's second law of motion.
The system in consideration has a mass $m=5$ g, spring constant $k=2$ N/m and damping coefficient $c=0.5$ Ns/m.
Given an external force $F$ and the acceleration of the system $\ddot{x}$,
the dynamics of the system can be written as the equality of forces acting on the mass:

$$
\begin{aligned}
  m\ddot{x} &= F - c\dot{x} - kx \\
  \implies \ddot{x} &= \frac{F}{m} - \frac{c}{m}\dot{x} - \frac{k}{m}x
\end{aligned}
$$

We have the state $[x \dot{x}]^T$ that contains the position and velocity of the mass, both of which are observed.
The control input $u=F$ is applied to the mass, yielding the following state-space model:

$$
\begin{aligned}
  \begin{bmatrix}
    \dot{x} \\
    \ddot{x}
  \end{bmatrix} &=
  \begin{bmatrix}
    0 & 1 \\
    -\frac{k}{m}  -\frac{c}{m}
  \end{bmatrix}
  \begin{bmatrix}
    x \\
    \dot{x}
  \end{bmatrix} +
  \begin{bmatrix}
    0 \\
    \frac{1}{m}
  \end{bmatrix} u \\
  y &=
  \begin{bmatrix}
    1 & 0 \\
    0 & 1
  \end{bmatrix}
  \begin{bmatrix}
    x \\
    \dot{x}
  \end{bmatrix}
\end{aligned}
$$

Thus, we have a standard continuous-time LTI system $\dot{x} = A_cx + B_cu$ and $y = C_cx$, where

\begin{equation}
  \begin{aligned}
    A_c &=
    \begin{bmatrix}
      0 & 1 \\
      -\frac{k}{m} & -\frac{c}{m}
    \end{bmatrix} \\
    B_c &=
    \begin{bmatrix}
      0 \\
      \frac{1}{m}
    \end{bmatrix} \\
    C_c &=
    \begin{bmatrix}
      1 & 0 \\
      0 & 1
    \end{bmatrix}
  \end{aligned}
\end{equation}

\subsection{LQR Controller} \label{lqr_ctrl}
The continuous-time system can be converted to discrete time using such that $x_{k+1} = A x_k + B u_k$ and $y_k = C x_k$ for a chosen sampling time $T_s$.
The $A$ and $B$ matrices for the discrete time system are then used to formulate the objective function for the LQR problem.

We set up an LQR controller to track the reference position and velocity of the mass-spring-damper system.
An LQR controller was chosen because it has a quadratic objective function that can be minimized analytically and gives us a
good reference for the trajectory optimization problem.

The LQR controller minimizes the objective function.

$$
\min_{u_0, u_1 ... u_{N-1}}J = \sum_{k=0}^{N-1} (e_k^T Q_e e_k + \Delta u_k^T R \Delta u_k)
$$

Where $\Delta u_0, \Delta u_1 ... \Delta u_{N-1}$ are the control inputs at each timestep of the trajectory,
$J$ is the objective function to be minimized, $N$ is the prediction horizon, $x_k$ is the state vector at time step $k$,
$u_k$ is the control input vector at time step $k$, $\Delta u_k = u_k - u_{k-1}$ is the change in control input at time step $k$,
$r_k$ is the reference output at time step $k$, $e_k = y_k - r_k = Cx - r_k$ is the error in the output at time step $k$,
$Q_e$ is the error penalty matrix and $R$ is the control penalty matrix.
Note that we can add a terminal penalty using the DARE solution for the LQR problem, but for simplicity, we will not consider it here.

To track the error $e_k$, we extend the state vector $x_k$ to include the control input $u_{k-1}$ and the reference output $r_k$.

$$
x_k^{ext} =
\begin{bmatrix}
  x_k \\
  u_{k-1} \\
  r_k
\end{bmatrix}
$$

With the resulting state-space model

\begin{equation}
  \begin{aligned}
    x_{k+1}^{ext} &=
    \begin{bmatrix}
      A & B & 0 \\
      0 & \mathbb{I}_{n_u \times n_u} & 0 \\
      0 & 0 & \mathbb{I}_{n_r \times n_r}
    \end{bmatrix}
    \begin{bmatrix}
      x_k \\
      u_{k-1} \\
      r_k
    \end{bmatrix} +
    \begin{bmatrix}
      B \\
      \mathbb{I}_{n_u \times n_u} \\
      0
    \end{bmatrix} \Delta u_k \\
  \end{aligned}
\end{equation}

with

$$
\begin{aligned}
  A^{ext} &=
  \begin{bmatrix}
    A & B & 0 \\
    0 & \mathbb{I}_{n_u \times n_u} & 0 \\
    0 & 0 & \mathbb{I}_{n_r \times n_r}
  \end{bmatrix} \\
  B^{ext} &=
  \begin{bmatrix}
    B \\
    \mathbb{I}_{n_u \times n_u} \\
    0
  \end{bmatrix}
\end{aligned}
$$

Similary, $Qe$ with the extended state $x_k^{ext}$ transforms to $Q$ such that $e_k^T Q_e e_k = x_k^{ext^T} Q x_k^{ext}$.

$$
\begin{aligned}
  e_k^T Q_e e_k &= (y_k - r_k)^T Q_e (y_k - r_k) \\
  &= \left(
    \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
    \end{bmatrix}
    \begin{bmatrix}
      x_k \\
      u_{k-1} \\
      r_k
  \end{bmatrix}\right)^T Q_e
  \left(
    \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
    \end{bmatrix}
    \begin{bmatrix}
      x_k \\
      u_{k-1} \\
      r_k
  \end{bmatrix}\right) \\
  &= x_k^{ext^T}
  \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
  \end{bmatrix}^T Q_e
  \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
  \end{bmatrix} x_k^{ext} \\
\end{aligned}
$$

\begin{equation}
  Q =
  \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
  \end{bmatrix}^T Q_e
  \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
  \end{bmatrix}
\end{equation}

For simplicity, from now on we refer to $x_k^{ext}$ as $x_k$, $A^{ext}$ as $A$ and $B^{ext}$ as $B$.
The objective function can now be written as

$$
J = \sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k
$$

Using the state transition formula

$$
\begin{aligned}
  x_1 &= A x_0 + B u_0 \\
  x_2 &= A x_1 + B u_1 = A(A x_0 + B u_0) + B u_1 = A^2 x_0 + A B u_0 + B u_1 \\
  \vdots \\
  x_N &= A x_{N-1} + B u_{N-1} = A^{N-1} x_0 + A^{N-2} B u_0 + A^{N-3} B u_1 + \ldots + B u_{N-1} \\
  \implies x_k &= A^k x_0 + \sum_{i=0}^{k-1} A^{k-1-i} B u_i
\end{aligned}
$$

We construct the matrices $X$, $U$, $S$ and $M$ such that $X = SU + Mx_0$.

$$
\begin{aligned}
  X &=
  \begin{bmatrix}
    x_1^{ext} \\
    x_2^{ext} \\
    \vdots \\
    x_N^{ext}
  \end{bmatrix} & \in \mathbb{R}^{Nn_x \times 1} \\
  U &=
  \begin{bmatrix}
    \Delta u_0 \\
    \Delta u_1 \\
    \vdots \\
    \Delta u_{N-1}
  \end{bmatrix} & \in \mathbb{R}^{Nn_u \times 1} \\
  S &=
  \begin{bmatrix}
    B & 0 & \ldots & 0 \\
    AB & B & \ldots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    A^{N-1} B & A^{N-2} B & \ldots & B
  \end{bmatrix} & \in \mathbb{R}^{Nn_x \times Nn_u} \\
  M &=
  \begin{bmatrix}
    A \\
    A^2 \\
    \vdots \\
    A^N
  \end{bmatrix} & \in \mathbb{R}^{Nn_x \times n_x}
\end{aligned}
$$

Similarly, the matrices $\bar{Q}$ and $\bar{R}$ are constructed

$$
\begin{aligned}
  \bar{Q} &=
  \begin{bmatrix}
    Q & 0 & \ldots & 0 \\
    0 & Q & \ldots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \ldots & 0
  \end{bmatrix} & \in \mathbb{R}^{Nn_x \times Nn_x} \\
  \bar{R} &=
  \begin{bmatrix}
    R & 0 & \ldots & 0 \\
    0 & R & \ldots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \ldots & R
  \end{bmatrix} & \in \mathbb{R}^{Nn_u \times Nn_u}
\end{aligned}
$$

The objective function can then be written as a quadratic function of the control inputs $U$

\begin{equation}
  \begin{aligned}
    J &= \sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k \\
    % \text{ (extra $x_0$ term because it is not in $X$)} \\
    &= X^T \bar{Q} X + U^T \bar{R} U + x_0^T Q x_0 \\
    &= (S U + M x_0)^T \bar{Q} (S U + M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } (A + B)^T = A^T + B^T \text{ and } (AB)^T = B^T A^T \\
    &= (U^T S^T + x_0^T M^T) \bar{Q} (S U + M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } A(B + C) = AB + AC \\
    &= (U^T S^T + x_0^T M^T) (\bar{Q} S U + \bar{Q} M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    &= U^T S^T \bar{Q} S U + U^T S^T \bar{Q} M x_0 + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } \bar{Q} \text{ is symmetric so it doesnt need to be transposed} \\
    &= U^T S^T \bar{Q} S U + (x_0^T M^T \bar{Q} S U)^T + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } x_0^T M^T \bar{Q} S U \text{ is a scalar(check its dimensions), so its transpose is itself} \\
    &= U^T S^T \bar{Q} S U + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{combining all quadratic and repeated terms} \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + 2 x_0^T M^T \bar{Q} S U + x_0^T(M^T \bar{Q} M + Q) x_0\\
  \end{aligned}
\end{equation}

Let

$$
\begin{aligned}
  H &= S^T \bar{Q} S + \bar{R} = H^T \\
  &\text{(quadratic multiplication by diagnonal($\bar{Q}$) results in a symmetric, R is symmetric)} \\
  q &= (x_0^T M^T \bar{Q} S)^T = S^T \bar{Q} M x_0 \\
  c &= x_0^T (M^T \bar{Q} M + Q) x_0
\end{aligned}
$$

The objective function can now be written as a quadratic function of the control inputs $U$

$$
J = U^T H U + 2 q^T U + c
$$

This has a gradient with respect to $U$ as

$$
\frac{\partial J}{\partial U} = 2 H U + 2 q^T
$$

Assuming a minimum exists, we can set the gradient to zero to obtain the optimal control input $U^*$

\begin{equation}
  \begin{aligned}
    \frac{\partial J}{\partial U} &= 2 H U + 2 q^T = 0 \\
    \implies U^* &= -H^{-1} q
  \end{aligned}
\end{equation}

\subsection{Stochastic LQR Controller} \label{lqr_ctrl_stoch}

We consider the case where the initial state $x_0$ is stochastic, with mean $\mu$ and covariance $\Sigma$.
Hence, the state vector $X$ is stochastic, as it propagates the randomness of $x_0$ forward.
The control input vector $U$ is deterministic. The objective function $J$ is now a random variable,
with an expected value $\mathbb{E}[J]$ and variance $Var[J]$.

\subsubsection{Solution of the Stochastic LQR controller}

The expected value of the objective function on all possible realizations of $x_0$ is

\begin{equation}
  \begin{aligned}
    \mathbb{E}[J] &= \mathbb{E}[\sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k] \\
    &= \mathbb{E}[X^T \bar{Q} X + U^T \bar{R} U + x_0^T Q x_0] \\
    &= \mathbb{E}[X^T \bar{Q} X] + \mathbb{E}[U^T \bar{R} U] + \mathbb{E}[x_0^T Q x_0] \\
    &= \mathbb{E}[(S U + M x_0)^T \bar{Q} (S U + M x_0)] + U^T \bar{R} U + \mathbb{E}[x_0^T Q x_0] \\
    &= \mathbb{E}[U^T S^T \bar{Q} S U + U^T S^T \bar{Q} M x_0 + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0] + U^T \bar{R} U + \mathbb{E}[x_0^T] Q \mathbb{E}[x_0] + \text{tr}(Q \text{Cov}[x_0]) \\
    &= U^T S^T \bar{Q} S U + \mathbb{E}[U^T S^T \bar{Q} M x_0] + \mathbb{E}[x_0^T M^T \bar{Q} S U] + \mathbb{E}[x_0^T M^T \bar{Q} M x_0] + U^T \bar{R} U + \mathbb{E}[x_0^T] Q \mathbb{E}[x_0] + \text{tr}(Q \text{Cov}[x_0]) \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + U^T S^T \bar{Q} M \mathbb{E}[x_0] + \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T M^T \bar{Q} M x_0] + \mathbb{E}[x_0^T] Q \mathbb{E}[x_0] + \text{tr}(Q \text{Cov}[x_0]) \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T] M^T \bar{Q} M \mathbb{E}[x_0] + \text{tr}(M^T \bar{Q} M \text{Cov}[x_0]) \dots \\
    & \quad + \mathbb{E}[x_0^T] Q \mathbb{E}[x_0] + \text{tr}(Q \text{Cov}[x_0]) \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + 2 \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T] (M^T \bar{Q} M + Q) \mathbb{E}[x_0] + \text{tr}((M^T \bar{Q} M + Q) \text{Cov}[x_0]) \\
  \end{aligned}
\end{equation}

Let

$$
\begin{aligned}
  H &= S^T \bar{Q} S + \bar{R} = H^T \\
  q &= (\mathbb{E}[x_0^T] M^T \bar{Q} S)^T = S^T \bar{Q} M \mathbb{E}[x_0] \\
  c &= \mathbb{E}[x_0^T] (M^T \bar{Q} M + Q) \mathbb{E}[x_0] + \text{tr}((M^T \bar{Q} M + Q) \text{Cov}[x_0])
\end{aligned}
$$

The expectation of objective function can be written as

$$
\mathbb{E}[J] = U^T H U + 2 q^T U + c
$$

This has a gradient with respect to $U$ as

$$
\frac{\partial \mathbb{E}[J]}{\partial U} = 2 H U + 2 q^T
$$

Assuming a minimum exists, we can set the gradient to zero to obtain the optimal control input $U^*$ that minimizes the expected value of the objective function.

\begin{equation}
  \begin{aligned}
    \frac{\partial \mathbb{E}[J]}{\partial U} &= 2 H U + 2 q^T = 0 \\
    \implies U^* &= -H^{-1} q
  \end{aligned}
\end{equation}

\subsubsection{Variance and Covariance of objective function in terms of initial state}

% ref for quadratic form: https://en.wikipedia.org/wiki/Quadratic_form_(statistics)
% ref:
% - https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf
% - https://math.stackexchange.com/questions/2163694/expectation-of-quartic-form-for-multivariate-gaussian/4247240#4247240
% - https://math.stackexchange.com/questions/1302882/variance-of-a-quadratic-form

The expected value of the objective function can be rewritten as

$$
\mathbb{E}[J] = K + \mathbb{E}[x_0^T] L + \mathbb{E}[x_0^T] N \mathbb{E}[x_0] + \text{tr}(N \text{Cov}[x_0]) \\
$$

where

$$
\begin{aligned}
  x_0 &\sim \mathcal{N}(\mu, \Sigma) \\
  K &= U^T(S^T \bar{Q} S + \bar{R}) U \\
  L &= 2 M^T \bar{Q} S U \\
  N &= M^T \bar{Q} M + Q = N^T \\
  &\text{(quadratic multiplication by diagnonal($\bar{Q}$) results in a symmetric, $Q$ is symmetric)} \\
\end{aligned}
$$

Using this, the variance can be calculated.

\begin{equation}
  \begin{aligned}
    Var[J] &= Var[K + x_0^T L + x_0^T N x_0] \\
    &\text{note: $K$ is deterministic, so its variance is 0} \\
    & \text{note: $x_0^T L$ is a scalar, $x_0^T L = L^T x_0$} \\
    &= Var[L^T x_0 + x_0^T N x_0] \\
    &= 2\text{tr}(N \text{Cov}[x_0] N \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N\text{Cov}[x_0]N\mathbb{E}[x_0] + 4 L^T \text{Cov}[x_0] N \mathbb{E}[x_0] + L^T \text{Cov}[x_0] L \\
  \end{aligned}
\end{equation}

To determine the covariance between the objectives of two solutions $U_1$ and $U_2$, in different objective functions
$J_1$ and $J_2$, we need to rewrite the objective functions to differentiate between them.

For $U_1$, the objective function is

$$
\begin{aligned}
  J_1(U_1) &= K_1 + x_0^T L_1 + x_0^T N_1 x_0 \\
  \text{where} \\
  K_1 &= U_1^T(S_1^T \bar{Q}_1 S_1 + \bar{R}_1) U_1 \\
  L_1 &= 2 M_1^T \bar{Q}_1 S_1 U_1 \\
  N_1 &= M_1^T \bar{Q}_1 M + Q_1 \\
  \text{and} \\
  & S_1, M_1, \bar{Q}_1, \bar{R}_1, Q_1 \text{ depend on the discrectization timestep of } J_1
\end{aligned}
$$

Similarly, for $U_2$, the objective function is

$$
\begin{aligned}
  J_2(U_2) &= K_2 + x_0^T L_2 + x_0^T N_2 x_0 \\
  \text{where} \\
  K_2 &= U_2^T(S_2^T \bar{Q}_2 S_2 + \bar{R}_2) U_2 \\
  L_2 &= 2 M_2^T \bar{Q}_2 S_2 U_2 \\
  N_2 &= M_2^T \bar{Q}_2 M + Q_2 \\
  \text{and} \\
  & S_2, M_2, \bar{Q}_2, \bar{R}_2, Q_2 \text{ depend on the discrectization timestep of } J_2
\end{aligned}
$$

% ref:
% - https://math.stackexchange.com/questions/1302882/variance-of-a-quadratic-form
% - https://stats.stackexchange.com/questions/303466/prove-that-mathrmcovxtax-xtbx-2-mathrmtra-sigma-b-sigma-4-mu
% - https://stats.stackexchange.com/questions/35084/covariance-of-a-linear-and-quadratic-form-of-a-multivariate-normal
The covariance between their objectives can be calculated as

\begin{equation}\label{eq:covariance}
  \begin{aligned}
    \text{Cov}[J_1(U_1), J_2(U_2)] &= \text{Cov}[K_1 + x_0^T L_1 + x_0^T N_1 x_0, K_2 + x_0^T L_2 + x_0^T N_2 x_0] \\
    &= \text{Cov}[x_0^T L_1 + x_0^T N_1 x_0, x_0^T L_2 + x_0^T N_2 x_0] \text{ (covariance is shift invariant)} \\
    &= \text{Cov}[x_0^T L_1, x_0^T L_2] + \text{Cov}[x_0^T L_1, x_0^T N_2 x_0] + \text{Cov}[x_0^T N_1 x_0, x_0^T L_2] + \text{Cov}[x_0^T N_1 x_0, x_0^T N_2 x_0] \\
  \end{aligned}
\end{equation}

Determining the covariance of each component in equation \ref{eq:covariance},

$$
\begin{aligned}
  \text{Cov}[x_0^T L_1, x_0^T L_2] &= \text{Cov}[L_1^T x_0, L_2^T x_0] \text{ transpose of a scalar is itself} \\
  &= L_1^T \text{Cov}[x_0] L_2 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P74, 3.2d.9
\begin{aligned}
  \text{Cov}[x_0^T L_1, x_0^T N_2 x_0] &= \text{Cov}[x_0^T N_2 x_0, L_1^T x_0] \text{ transpose of a scalar is itself} \\
  &= 2 \mathbb{E}[x_0^T] N_2 \text{Cov}[x_0] L_1 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P74, 3.2d.9
\begin{aligned}
  \text{Cov}[x_0^T N_1 x_0, x_0^T L_2] &= \text{Cov}[x_0^T N_1 x_0, L_2^T x_0] \text{ transpose of a scalar is itself} \\
  &= 2 \mathbb{E}[x_0^T] N_1 \text{Cov}[x_0] L_2 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P75, 3.2d.12
\begin{aligned}
  \text{Cov}[x_0^T N_1 x_0, x_0^T N_2 x_0] &= 2 \text{tr}(N_1 \text{Cov}[x_0] N_2 \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N_1\text{Cov}[x_0]N_2\mathbb{E}[x_0] \\
\end{aligned}
$$

Combining these, we get the covariance as

\begin{equation}
  \begin{aligned}
    \text{Cov}[J_1(U_1), J_2(U_2)] &= L_1^T \text{Cov}[x_0] L_2 + 2 \mathbb{E}[x_0^T] N_2 \text{Cov}[x_0] L_1 + 2 \mathbb{E}[x_0^T] N_1 \text{Cov}[x_0] L_2 \hdots \\
    & \quad + 2 \text{tr}(N_1 \text{Cov}[x_0] N_2 \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N_1\text{Cov}[x_0]N_2\mathbb{E}[x_0]
  \end{aligned}
\end{equation}

\section{Monte Carlo with Control Variates}

The objective of this paper is to reduce the variance of the objective function estimation under sample average approximation.
A Monte Carlo(MC) simulation can be used to estimate the expected value of the objective function, but a control variate(CV) approach
would reduce the variance with the same computational cost. In the absence of an analytical expression of the expected value of the
objective function, an approximate control variate(ACV) approach is also proposed. The CV estimator will also serve as
the benchmark for the ACV estimator, since it is the best possible variance reduction that can be achieved with the ACV estimator.

In order to formulate the CV and ACV approaches, we need a low-fidelity(LF) model of the system that correlates well
with the high-fidelity(HF) model. The LF model should be computationally cheaper to evaluate than the
HF model, and hence can be used as a control variate to reduce the variance of the objective function
estimation.

For this paper, the HF model is the LQR controller described in section \ref{lqr_ctrl_stoch}, with a time
discrectization of 0.05s and the LF model is the same LQR controller but with a time discrectization of 0.5s.
The solution for the LQR controller with the LF model contains fewer elements than the HF model due to there being
fewer time steps for the same prediction horizon. For CV/ACV construction, we need to be able to use the same
HF control input in the LF model for the estimators to be effective.

Hence, it is necessary to downsample the HF solution if we want to use it with the LF model in the CV/ACV estimators.

To downsample $U_h \rightarrow U_l$, we can either restrict the dimensions of $U_h$ to match $U_l$ or average the elements of $U_h$ to match the dimensions of $U_l$.
In case of restriction, $U_{hlr} = T_{hlr} U_h$ while in case of averaging, $U_{hla} = T_{hla} U_h$.
$T_{hlr}$, $T_{hla} \in \mathbb{R}^{n_{U_l} \times n_{U_h}}$.

$$
T_{hlr} =
\begin{bmatrix}
  1 & 0 & \ldots & 0 & 0 \\
  0 & \ldots & 1 & \ldots & 0 \\
  \vdots & \ddots & \vdots & \ddots & \vdots \\
  0 & 0 & \ldots & 0 & 1 \\
\end{bmatrix}
$$

Where the number of columns after which the next one is selected is determined by the ratio $r_{hl} = n_{U_h} / n_{U_l}$.

$$
T_{hla} =
\begin{bmatrix}
  r_{lh} & \ldots & 0 & 0 & 0 \\
  0 & \ldots & r_{lh} & \ldots & 0 \\
  \vdots & \ddots & \vdots & \vdots & \vdots \\
  0 & 0 & 0 & r_{lh} & \ldots \\
\end{bmatrix}
$$

Where $r_{lh} = n_{U_l} / n_{U_h}$ is repeated $r_{hl}$ times in each row.

Let $J_h$ and $J_l$ be the objective functions of the HF and LF models respectively. Then, for us to construct a
CV/ACV estimator, we need to consider the correlation between them. With a higher correlation, we get a greater variance reduction
We calculate the Pearson correlation coefficient $\rho$ using the covariance of the objectives
as described in section \ref{lqr_ctrl_stoch}.

\begin{equation}
  \rho(J(U_h), J(U_l)) = \frac{\text{Cov}(J(U_h), J(U_l))}{\sigma_h \sigma_l}
\end{equation}

\subsection{CV and ACV Construction}

First, we define the Monte Carlo estimator $S_n^{MC}(J_h(U_h, x_0))$ for the HF objective as a baseline.

$$
S_n^{MC}(J_h(U_h, x_0)) = \frac{1}{n} \sum_{i=1}^{n} J_h(U_h, x_0^{(i)})
$$

Where $n$ is the number of samples of $x_0$ used in the MC estimate.

The CV estimator $S_{n_{cv}}^{CV}(J_h, J_l)$ is constructed using both the HF and LF objectives, and the
analytical expectation of the LF objective function.

$$
S_{n_{cv}}^{CV}(J_h, J_l) = S_{n_{cv}}^{MC}(J_h(U_h, x_0)) + \alpha (S_{n_{cv}}^{MC}(J_l(U_{hla}, x_0)) - \mathbb{E}[J_l(U_{hla}, x_0)])
$$

Choosing $n_{cv}$ samples of $x_0$ to equal the cost of $S_n^{MC}(J_h(U_h, x_0))$ and reusing the same samples for the HF and LF objectives.
The control variate coefficient $\alpha$ can be calculated analytically using the actual mean and covariance of $x_0$
and the equations in section \ref{lqr_ctrl_stoch}.

$$
\alpha = -\frac{\text{Cov}(J_h(U_h, x_0), J_l(U_{hla}, x_0))}{\text{Var}[J_l(U_{hla}, x_0)]}
$$

Finally, the ACV estimator $S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l)$ is constructed using both the HF and LF objectives but with
a statistical estimate of the expectation of the LF objective function.

$$
S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l) = S_{n_{acv}}^{MC}(J_h(U_h, x_0)) + \alpha (S_{n_{acv}}^{MC}(J_l(U_{hla}, x_0)) - S_{m_{acv}}^{MC}(J_l(U_{hla}, x_0)))
$$

Choosing $n_{acv} + m_{acv}$ samples of $x_0$ to equal the cost of $S_n^{MC}(J_h(U_h, x_0))$ and reusing the same samples
for the HF and LF objectives in the first two terms. The coefficient $\alpha$ can be calculated statistically with $n_{acv}$ samples of $x_0$.

We expect the CV estimator to have a lower variance than the MC estimator. Howevever, since it is not possible
to have an analytical expression for the expected value of most objective functions used for trajectory optimization,
especially with constraints, the CV estimator is not always possible to construct. The ACV estimator is a compromise
that converges to the variance of the CV estimator as $m_{acv} \rightarrow \infty$.

\subsection{Numerical optimization}

To optimize trajectory using LQR, to obtain the optimal control inputs $U_h^*$ under stochastic initial conditions $x_0$,
we need to minimize the expected value of the objective function $\mathbb{E}[J_h(U_h, x_0)]$. We do this using off-the-shelf
numerical optimization algorithms present in MATLAB, such as fmincon, fminunc, etc. An important point to consider
is that the variance of the objective function estimation depends on the number of samples of $x_0$ used as well as
the correlation between the HF and LF objectives. We exploit the fact that as the numerical optimizer iterates, it computes
$U_h$ at every iteration and for us to achieve the maximum correlation between the HF and LF objectives, we can use
choose a $U_h$ which when downsampled to $U_l$ gives us the highest corelation $\rho(J_h(U_h, x_0), J_l(U_{hla}, x_0))$.
Hence, at each iteration of the CV/ACV estimators we use the $U_h$ at the current iteration while we use $U_{hla}$ from
the iteration with the highest correlation. This $U_{hla}$ at the iteration with the highest correlation is
$U_{hla}^{max}$. The LF objective is then calculated using this $U_{hla}^{max}$ to be used in the CV/ACV estimators to get the maximum variance reduction.

For numerical optimization using the CV estimator, we save the $U_{hla}^{(k)}$ for every iteration $k$ in an array
so that they can be used to calculate the correlation in all future iterations.

\begin{algorithm}
  \caption{Numerical optimization with CV estimator}
  \begin{algorithmic}
    \Require $J_h, J_l, n_{cv}, U_0, x_0 \mu, \Sigma, k_{max}$
    \State $k \gets 0$ (iteration counter)
    \State $U \gets U_0$ initialize the numerical optimizer
    \While{numerical optimizer has not converged $\wedge$ $k < k_{max}$}
    \State $U_h \gets$ $U$ from the numerical optimizer
    \State $U_{hla}^{(k)} \gets T_{hla} U_h$
    \State $U_{hla}^{max} \gets \underset{U_{hla}(j)} \max \{\rho(J_h(U_h, x_0), J_l(U_{hla}^{(j)}, x_0))\}_{j=1}^k$
    \State $\text{Cov}_{hl} \gets \text{Cov}(J_h(U_h, x_0), J_l(U_{hla}^{max}, x_0))$ calculated analytically using $\mu, \Sigma$
    \State $\text{Var}_l \gets \text{Var}[J_l(U_{hla}^{max}, x_0)]$ calculated analytically using $\mu, \Sigma$
    \State $\alpha \gets -\frac{\text{Cov}_{hl}}{\text{Var}_l}$
    \State $\mathbb{E}[J_l(U_{hla}^{max}, x_0)] \gets$ calculated analytically using $\mu, \Sigma$
    \State $S_{n_{cv}}^{CV}(J_h, J_l) \gets S_{n_{cv}}^{MC}(J_h(U_h, x_0)) + \alpha (S_{n_{cv}}^{MC}(J_l(U_{hla}^{max}, x_0)) - \mathbb{E}[J_l(U_{hla}^{max}, x_0)])$
    \State $k \gets k + 1$
    \State $S_{n_{cv}}^{CV}(J_h, J_l)$ is passed to the numerical optimizer for computing gradients for the next iteration
    \EndWhile
  \end{algorithmic}
\end{algorithm}

Numerical optimization using ACV is similar to CV, but all the terms are calculated statistically using $n_{acv}$ and separate
$m_{acv}$ samples of $x_0$.

\begin{algorithm}
  \caption{Numerical optimization with ACV estimator}
  \begin{algorithmic}
    \Require $J_h, J_l, n_{acv}, m_{acv}, U_0, x_0, k_{max}$
    \State $k \gets 0$ (iteration counter)
    \State $U \gets U_0$ initialize the numerical optimizer
    \While{numerical optimizer has not converged $\wedge$ $k < k_{max}$}
    \State $U_h \gets$ $U$ from the numerical optimizer
    \State $U_{hla}^{(k)} \gets T_{hla} U_h$
    \State $U_{hla}^{max} \gets \underset{U_{hla}(j)} \max \{\rho(J_h(U_h, x_0), J_l(U_{hla}^{(j)}, x_0))\}_{j=1}^k$
    \State $\text{Cov}_{hl} \gets \text{Cov}(J_h(U_h, x_0), J_l(U_{hla}^{max}, x_0))$ calculated statistically using $n_{acv}$ samples
    \State $\text{Var}_l \gets \text{Var}[J_l(U_{hla}^{max}, x_0)]$ calculated statistically using $n_{acv}$ samples
    \State $\alpha \gets -\frac{m_{acv}}{m_{acv} + n_{acv}} \frac{\text{Cov}_{hl}}{\text{Var}_l}$ calculated statistically using $n_{acv}$ samples
    \State $\mathbb{E}[J_l(U_{hla}^{max}, x_0)] \gets \frac{1}{m_{acv}} \sum_{i=n_{acv}}^{n_{acv}+m_{acv}} J_l(U_{hla}^{max}, x_0^{(i)})$
    \State $S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l) \gets S_{n_{acv}}^{MC}(J_h(U_h, x_0)) + \alpha (S_{n_{acv}}^{MC}(J_l(U_{hla}^{max}, x_0)) - S_{m_{acv}}^{MC}(J_l(U_{hla}^{max}, x_0)))$
    \State $k \gets k + 1$
    \State $S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l)$ is passed to the numerical optimizer for computing gradients for the next iteration
    \EndWhile
  \end{algorithmic}
\end{algorithm}

\end{document}
