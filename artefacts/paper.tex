\documentclass{article}
\usepackage[a4paper, total={7in, 8in}]{geometry}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath} % Required for some math elements
\usepackage{hyperref} % Required for hyperlinks
\usepackage{amssymb} % Required for probability symbols
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{MultifidelityTrajectoryOptimization}
\author{goroda }
\date{October 2024}

\begin{document}

\maketitle

\begin{abstract}
  TODO: abstract
\end{abstract}

\section{Introduction}
TODO: introduction
\section{Background}
TODO: background

\section{Problem Formulation}
In this paper, we propose a multifidelity approach to stochastic trajectory optimization with sample average approximation.
The objective is to minimize the expected value of the objective function, which is chosen an an LQR controller for a mass-spring-damper system.
A mass-spring-damper system is considered for ease of modelling, since the focus is on the multifidelity approach
and not on the complexity of the system dynamics.
The LQR controller attempts to find the optimal trajectory for tracking a reference position and velocity of the mass-spring-damper system.
This section describes how the dynamics for the mass-spring-damper is set up, along with the controller design and objective function for the trajectory optimization problem.

\subsection{Mass-Spring-Damper System}
The mass-spring-damper system is a second order system that can be modelled using Newton's second law of motion.
The system in consideration has a mass $m=5$ g, spring constant $k=2$ N/m and damping coefficient $c=0.5$ Ns/m.
Given an external force $F$ and the acceleration of the system $\ddot{x}$, we have the state $[x \dot{x}]^T$
that contains the position and velocity of the mass, both of which are observed.
The control input $u=F$ is applied to the mass, yielding the following state-space model:

$$
\begin{aligned}
  \begin{bmatrix}
    \dot{x} \\
    \ddot{x}
  \end{bmatrix} &=
  \begin{bmatrix}
    0 & 1 \\
    -\frac{k}{m}  -\frac{c}{m}
  \end{bmatrix}
  \begin{bmatrix}
    x \\
    \dot{x}
  \end{bmatrix} +
  \begin{bmatrix}
    0 \\
    \frac{1}{m}
  \end{bmatrix} u \\
  y &=
  \begin{bmatrix}
    1 & 0 \\
    0 & 1
  \end{bmatrix}
  \begin{bmatrix}
    x \\
    \dot{x}
  \end{bmatrix}
\end{aligned}
$$

Thus, we have a standard continuous-time LTI system $\dot{x} = A_cx + B_cu$ and $y = C_cx$, which can be discretized
into a discrete-time LTI system $x_{k+1} = Ax_k + Bu_k$ and $y_k = Cx_k$ using a sampling time $T_s$. We can now use
this discrete-time system to set up the LQR controller.

\subsection{LQR Controller} \label{lqr_ctrl}
The continuous-time system can be converted to discrete time using such that $x_{k+1} = A x_k + B u_k$ and $y_k = C x_k$ for a chosen sampling time $T_s$.
The $A$ and $B$ matrices for the discrete time system are then used to formulate the objective function for the LQR problem.

We set up an LQR controller to track the reference position and velocity of the mass-spring-damper system.
An LQR controller was chosen because it has a quadratic objective function that can be minimized analytically and gives us a
good reference for the trajectory optimization problem.

The LQR controller minimizes the objective function.

$$
\min_{u_0, u_1 ... u_{N-1}}J = \sum_{k=0}^{N-1} (e_k^T Q_e e_k + \Delta u_k^T R \Delta u_k)
$$

Where $\Delta u_0, \Delta u_1 ... \Delta u_{N-1}$ are the control inputs at each timestep of the trajectory,
$J$ is the objective function to be minimized, $N$ is the prediction horizon, $x_k$ is the state vector at time step $k$,
$u_k$ is the control input vector at time step $k$, $\Delta u_k = u_k - u_{k-1}$ is the change in control input at time step $k$,
$r_k$ is the reference output at time step $k$, $e_k = y_k - r_k = Cx - r_k$ is the error in the output at time step $k$,
$Q_e$ is the error penalty matrix and $R$ is the control penalty matrix.
Note that we can add a terminal penalty using the DARE solution for the LQR problem, but for simplicity, we will not consider it here.

To track the error $e_k$, we extend the state vector $x_k$ to include the control input $u_{k-1}$ and the reference output $r_k$.

$$
x_k^{ext} =
\begin{bmatrix}
  x_k \\
  u_{k-1} \\
  r_k
\end{bmatrix}
$$

And stack the state vectors $x_k^{ext}$ for all time steps $k$ to get the extended state vector $X$.
The control input is also stacked to get the control input vector $U$.

$$
X =
\begin{bmatrix}
  x_1^{ext} \\
  x_2^{ext} \\
  \vdots \\
  x_N^{ext}
\end{bmatrix}  \in \mathbb{R}^{Nn_x \times 1}, \quad
U =
\begin{bmatrix}
  \Delta u_0 \\
  \Delta u_1 \\
  \vdots \\
  \Delta u_{N-1}
\end{bmatrix}  \in \mathbb{R}^{Nn_u \times 1}
$$

Similary, $Qe$ with the extended state $x_k^{ext}$ transforms to $Q$ such that $e_k^T Q_e e_k = x_k^{ext^T} Q x_k^{ext}$.

For simplicity, from now on we refer to $x_k^{ext}$ as $x_k$, $A^{ext}$ as $A$ and $B^{ext}$ as $B$.
The objective function can now be written as

$$
J = \sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k
$$

Using the state transition formula, we can write the stacked state vector $X$ as $X = SU + Mx_0$.
Here $S \in \mathbb{R}^{Nn_x \times Nn_u}$ and $M \in \mathbb{R}^{Nn_x \times n_x}$ are matrices that depend on the
state transition matrices $A$ and $B$.
Similarly, the matrices $\bar{Q} \in \mathbb{R}^{Nn_x \times Nn_x}$ and $\bar{R} \in \mathbb{R}^{Nn_u \times Nn_u}$
are constructed using the penalty matrices $Q$ and $R$. The objective function then can then be written as a quadratic function of the control inputs $U$

\begin{equation}
  \begin{aligned}
    J &= \sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k \\
    % \text{ (extra $x_0$ term because it is not in $X$)} \\
    &= X^T \bar{Q} X + U^T \bar{R} U + x_0^T Q x_0 \\
    &= (S U + M x_0)^T \bar{Q} (S U + M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } (A + B)^T = A^T + B^T \text{ and } (AB)^T = B^T A^T \\
    &= (U^T S^T + x_0^T M^T) \bar{Q} (S U + M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } A(B + C) = AB + AC \\
    &= (U^T S^T + x_0^T M^T) (\bar{Q} S U + \bar{Q} M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    &= U^T S^T \bar{Q} S U + U^T S^T \bar{Q} M x_0 + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } \bar{Q} \text{ is symmetric so it doesnt need to be transposed} \\
    &= U^T S^T \bar{Q} S U + (x_0^T M^T \bar{Q} S U)^T + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } x_0^T M^T \bar{Q} S U \text{ is a scalar(check its dimensions), so its transpose is itself} \\
    &= U^T S^T \bar{Q} S U + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{combining all quadratic and repeated terms} \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + 2 x_0^T M^T \bar{Q} S U + x_0^T(M^T \bar{Q} M + Q) x_0\\
  \end{aligned}
\end{equation}

Let

$$
\begin{aligned}
  H &= S^T \bar{Q} S + \bar{R} = H^T \\
  &\text{(quadratic multiplication by diagnonal($\bar{Q}$) results in a symmetric, R is symmetric)} \\
  q &= (x_0^T M^T \bar{Q} S)^T = S^T \bar{Q} M x_0 \\
  c &= x_0^T (M^T \bar{Q} M + Q) x_0
\end{aligned}
$$

The objective function can now be written as a quadratic function of the control inputs $U$

$$
J = U^T H U + 2 q^T U + c
$$

This has a gradient with respect to $U$ as

$$
\frac{\partial J}{\partial U} = 2 H U + 2 q^T
$$

Assuming a minimum exists, we can set the gradient to zero to obtain the optimal control input $U^*$

\begin{equation}
  \begin{aligned}
    \frac{\partial J}{\partial U} &= 2 H U + 2 q^T = 0 \\
    \implies U^* &= -H^{-1} q
  \end{aligned}
\end{equation}

\subsection{Stochastic LQR Controller} \label{lqr_ctrl_stoch}

We consider the case where the initial state $x_0$ is stochastic, with mean $\mu$ and covariance $\Sigma$.
Hence, the state vector $X$ is stochastic, as it propagates the randomness of $x_0$ forward.
The control input vector $U$ is deterministic. The objective function $J$ is now a random variable,
with an expected value $\mathbb{E}[J]$ and variance $Var[J]$.

\subsubsection{Solution of the Stochastic LQR controller}

The expected value of the objective function on all possible realizations of $x_0$ is

\begin{equation}
  \begin{aligned}
    \mathbb{E}[J] &= \mathbb{E}[\sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k] \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + 2 \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T] (M^T \bar{Q} M + Q) \mathbb{E}[x_0] + \text{tr}((M^T \bar{Q} M + Q) \text{Cov}[x_0]) \\
  \end{aligned}
\end{equation}

Let

$$
\begin{aligned}
  H &= S^T \bar{Q} S + \bar{R} = H^T \\
  q &= (\mathbb{E}[x_0^T] M^T \bar{Q} S)^T = S^T \bar{Q} M \mathbb{E}[x_0] \\
  c &= \mathbb{E}[x_0^T] (M^T \bar{Q} M + Q) \mathbb{E}[x_0] + \text{tr}((M^T \bar{Q} M + Q) \text{Cov}[x_0])
\end{aligned}
$$

The expectation of objective function can be written as

$$
\mathbb{E}[J] = U^T H U + 2 q^T U + c
$$

This has a gradient with respect to $U$ as

$$
\frac{\partial \mathbb{E}[J]}{\partial U} = 2 H U + 2 q^T
$$

Assuming a minimum exists, we can set the gradient to zero to obtain the optimal control input $U^*$ that minimizes the expected value of the objective function.

\begin{equation}
  \begin{aligned}
    \frac{\partial \mathbb{E}[J]}{\partial U} &= 2 H U + 2 q^T = 0 \\
    \implies U^* &= -H^{-1} q
  \end{aligned}
\end{equation}

\subsubsection{Variance and Covariance of objective function in terms of initial state}

% ref for quadratic form: https://en.wikipedia.org/wiki/Quadratic_form_(statistics)
% ref:
% - https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf
% - https://math.stackexchange.com/questions/2163694/expectation-of-quartic-form-for-multivariate-gaussian/4247240#4247240
% - https://math.stackexchange.com/questions/1302882/variance-of-a-quadratic-form

The expected value of the objective function can be rewritten as

$$
\mathbb{E}[J] = K + \mathbb{E}[x_0^T] L + \mathbb{E}[x_0^T] N \mathbb{E}[x_0] + \text{tr}(N \text{Cov}[x_0]) \\
$$

where

$$
\begin{aligned}
  x_0 &\sim \mathcal{N}(\mu, \Sigma) \\
  K &= U^T(S^T \bar{Q} S + \bar{R}) U \\
  L &= 2 M^T \bar{Q} S U \\
  N &= M^T \bar{Q} M + Q = N^T \\
  &\text{(quadratic multiplication by diagnonal($\bar{Q}$) results in a symmetric, $Q$ is symmetric)} \\
\end{aligned}
$$

Using this, the variance can be calculated.

\begin{equation}
  \begin{aligned}
    Var[J] &= Var[K + x_0^T L + x_0^T N x_0] \\
    &\text{note: $K$ is deterministic, so its variance is 0} \\
    & \text{note: $x_0^T L$ is a scalar, $x_0^T L = L^T x_0$} \\
    &= Var[L^T x_0 + x_0^T N x_0] \\
    &= 2\text{tr}(N \text{Cov}[x_0] N \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N\text{Cov}[x_0]N\mathbb{E}[x_0] + 4 L^T \text{Cov}[x_0] N \mathbb{E}[x_0] + L^T \text{Cov}[x_0] L \\
  \end{aligned}
\end{equation}

To determine the covariance between the objectives of two solutions $U_1$ and $U_2$, in different objective functions
$J_1$ and $J_2$, we need to rewrite the objective functions to differentiate between them.

For $U_1$, the objective function is

$$
\begin{aligned}
  J_1(U_1) &= K_1 + x_0^T L_1 + x_0^T N_1 x_0 \\
  \text{where} \\
  K_1 &= U_1^T(S_1^T \bar{Q}_1 S_1 + \bar{R}_1) U_1 \\
  L_1 &= 2 M_1^T \bar{Q}_1 S_1 U_1 \\
  N_1 &= M_1^T \bar{Q}_1 M + Q_1 \\
  \text{and} \\
  & S_1, M_1, \bar{Q}_1, \bar{R}_1, Q_1 \text{ depend on the discrectization timestep of } J_1
\end{aligned}
$$

Similarly, for $U_2$, the objective function is

$$
\begin{aligned}
  J_2(U_2) &= K_2 + x_0^T L_2 + x_0^T N_2 x_0 \\
  \text{where} \\
  K_2 &= U_2^T(S_2^T \bar{Q}_2 S_2 + \bar{R}_2) U_2 \\
  L_2 &= 2 M_2^T \bar{Q}_2 S_2 U_2 \\
  N_2 &= M_2^T \bar{Q}_2 M + Q_2 \\
  \text{and} \\
  & S_2, M_2, \bar{Q}_2, \bar{R}_2, Q_2 \text{ depend on the discrectization timestep of } J_2
\end{aligned}
$$

% ref:
% - https://math.stackexchange.com/questions/1302882/variance-of-a-quadratic-form
% - https://stats.stackexchange.com/questions/303466/prove-that-mathrmcovxtax-xtbx-2-mathrmtra-sigma-b-sigma-4-mu
% - https://stats.stackexchange.com/questions/35084/covariance-of-a-linear-and-quadratic-form-of-a-multivariate-normal
The covariance between their objectives can be calculated as

\begin{equation}\label{eq:covariance}
  \begin{aligned}
    \text{Cov}[J_1(U_1), J_2(U_2)] &= \text{Cov}[K_1 + x_0^T L_1 + x_0^T N_1 x_0, K_2 + x_0^T L_2 + x_0^T N_2 x_0] \\
    &= \text{Cov}[x_0^T L_1 + x_0^T N_1 x_0, x_0^T L_2 + x_0^T N_2 x_0] \text{ (covariance is shift invariant)} \\
    &= \text{Cov}[x_0^T L_1, x_0^T L_2] + \text{Cov}[x_0^T L_1, x_0^T N_2 x_0] + \text{Cov}[x_0^T N_1 x_0, x_0^T L_2] + \text{Cov}[x_0^T N_1 x_0, x_0^T N_2 x_0] \\
  \end{aligned}
\end{equation}

Determining the covariance of each component in equation \ref{eq:covariance},

$$
\begin{aligned}
  \text{Cov}[x_0^T L_1, x_0^T L_2] &= \text{Cov}[L_1^T x_0, L_2^T x_0] \text{ transpose of a scalar is itself} \\
  &= L_1^T \text{Cov}[x_0] L_2 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P74, 3.2d.9
\begin{aligned}
  \text{Cov}[x_0^T L_1, x_0^T N_2 x_0] &= \text{Cov}[x_0^T N_2 x_0, L_1^T x_0] \text{ transpose of a scalar is itself} \\
  &= 2 \mathbb{E}[x_0^T] N_2 \text{Cov}[x_0] L_1 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P74, 3.2d.9
\begin{aligned}
  \text{Cov}[x_0^T N_1 x_0, x_0^T L_2] &= \text{Cov}[x_0^T N_1 x_0, L_2^T x_0] \text{ transpose of a scalar is itself} \\
  &= 2 \mathbb{E}[x_0^T] N_1 \text{Cov}[x_0] L_2 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P75, 3.2d.12
\begin{aligned}
  \text{Cov}[x_0^T N_1 x_0, x_0^T N_2 x_0] &= 2 \text{tr}(N_1 \text{Cov}[x_0] N_2 \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N_1\text{Cov}[x_0]N_2\mathbb{E}[x_0] \\
\end{aligned}
$$

Combining these, we get the covariance as

\begin{equation}
  \begin{aligned}
    \text{Cov}[J_1(U_1), J_2(U_2)] &= L_1^T \text{Cov}[x_0] L_2 + 2 \mathbb{E}[x_0^T] N_2 \text{Cov}[x_0] L_1 + 2 \mathbb{E}[x_0^T] N_1 \text{Cov}[x_0] L_2 \hdots \\
    & \quad + 2 \text{tr}(N_1 \text{Cov}[x_0] N_2 \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N_1\text{Cov}[x_0]N_2\mathbb{E}[x_0]
  \end{aligned}
\end{equation}

\section{Monte Carlo with Control Variates}

For optimizing the trajectory of system under uncertainty, a common approach is to compute the expectation of the objective
function of a trajectory is by doing sample average approximation, where we propagate the trajectory with multiples samples
of the random variable, and take the average of all samples in a numerical optimizer to determine the optimal control inputs.
The most straighforward way to compute the expectation of the trajectory's objective function is to use Monte Carlo (MC) estimator.
When using a MC estimator, the variance of the estimated trajectory objective is related to the variance of the trajectory's
objective function in the following way.

$$
\text{Var}[S_n^{MC}(J)] = \frac{\text{Var}[J]}{n}
$$

Where $S_n^{MC}(J)$ is the MC estimator of the objective function $J$ with $n$ samples of the random variable.
The solution to the stochastic LQR controller, $U^*$ can be written as a function of the initial state $x_0$.

$$
\begin{aligned}
  U^* &= -H^{-1} q \\
  \mathbb{E}[U^*] &= \mathbb{E}[-H^{-1} q] \\
  &= -H^{-1} \mathbb{E}[q] \text{ ($H$ is deterministic)} \\
  &= -H^{-1} \mathbb{E}[S^T \bar{Q} M x_0] \\
  &= -H^{-1} S^T \bar{Q} M \mathbb{E}[x_0] \\
  \text{Cov}[U^*] &= \text{Cov}[-H^{-1} q] \\
  &= H^{-1} \text{Cov}[q] H^{-1} \text{ ($H$ is symmetric)} \\
  &= H^{-1} \text{Cov}[S^T \bar{Q} M x_0] H^{-1} \\
  &= H^{-1} S^T \bar{Q} M \text{Cov}[x_0] M^T \bar{Q} S H^{-1} \text{($\bar{Q}$ is symmetric)} \\
\end{aligned}
$$

The objective of this paper is to reduce the variance of the objective function estimation under sample average approximation,
thus, thereby reducing the covariance of the solution $U^*$ given a finite cost of computation.

A control variate (CV) estimator is a variance reduction technique that uses the correlation between the objective function
and another function to reduce the variance of the objective function estimation. Its variance has the form

$$
\text{Var}[S_{n_{cv}}^{CV}(J_h, J_l)] = \text{Var}[J_h] (1 - \rho^2)
$$

Where $J_h$ and $J_l$ are the high and low fidelity models of the objective function, $\rho$ is the Pearson correlation
coefficient between the high and low fidelity models, and $S_{n_{cv}}^{CV}(J_h, J_l)$ is the CV estimator of the objective
function $J_h$ using the low fidelity model $J_l$.

The CV estimator requires the analytical expectation of the expectation of the low fidelity model, and the covariance between
the high and low fidelity models. This might not be available in practice, and hence, an alternative is the approximate
control variate (ACV) estimator. The ACV estimator uses the statistical estimate of the expectation and covariance
of the low fidelity model, and has the variance

$$
\text{Var}[S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l)] = \text{Var}[J_h] (1 - \frac{m_{acv}}{m_{acv} + n_{acv}} \rho^2)
$$

Where $m_{acv}$ and $n_{acv}$ are the number of samples used to estimate the expectation and covariance of the low fidelity model,

In order to formulate the CV and ACV approaches, we need a low-fidelity(LF) model of the system that correlates well
with the high-fidelity(HF) model. The LF model should be computationally cheaper to evaluate than the
HF model, and hence can be evaluated with a lot more samples of $x_0$ than the HF model for the same cost.
Thus, we use the LF model as a control variate to reduce the variance of the objective function
estimation.

For this paper, the HF model is the LQR controller described in section \ref{lqr_ctrl_stoch}, with a time
discrectization of 0.05s and the LF model is the same LQR controller but with a time discrectization of 0.5s.
The solution for the LQR controller with the LF model contains fewer elements than the HF model due to there being
fewer time steps for the same prediction horizon. For CV/ACV construction, we need to be able to use the same
HF control input in the LF model for the estimators to be effective.

Hence, it is necessary to downsample the HF solution if we want to use it with the LF model in the CV/ACV estimators.

To downsample $U_h \rightarrow U_l$, we can either restrict the dimensions of $U_h$ to match $U_l$ or average the elements of $U_h$ to match the dimensions of $U_l$.
In case of restriction, $U_{hlr} = T_{hlr} U_h$ while in case of averaging, $U_{hla} = T_{hla} U_h$.
$T_{hlr}$, $T_{hla} \in \mathbb{R}^{n_{U_l} \times n_{U_h}}$.

$$
T_{hlr} =
\begin{bmatrix}
  1 & 0 & \ldots & 0 & 0 \\
  0 & \ldots & 1 & \ldots & 0 \\
  \vdots & \ddots & \vdots & \ddots & \vdots \\
  0 & 0 & \ldots & 0 & 1 \\
\end{bmatrix}
$$

Where the number of columns after which the next one is selected is determined by the ratio $r_{hl} = n_{U_h} / n_{U_l}$.

$$
T_{hla} =
\begin{bmatrix}
  r_{lh} & \ldots & 0 & 0 & 0 \\
  0 & \ldots & r_{lh} & \ldots & 0 \\
  \vdots & \ddots & \vdots & \vdots & \vdots \\
  0 & 0 & 0 & r_{lh} & \ldots \\
\end{bmatrix}
$$

Where $r_{lh} = n_{U_l} / n_{U_h}$ is repeated $r_{hl}$ times in each row.

Let $J_h$ and $J_l$ be the objective functions of the HF and LF models respectively. Then, for us to construct a
CV/ACV estimator, we need to consider the correlation between them. With a higher correlation, we get a greater variance reduction
We calculate the Pearson correlation coefficient $\rho$ using the covariance of the objectives
as described in section \ref{lqr_ctrl_stoch}.

\begin{equation}
  \rho(J(U_h), J(U_l)) = \frac{\text{Cov}(J(U_h), J(U_l))}{\sigma_h \sigma_l}
\end{equation}

\subsection{CV and ACV Construction}

First, we define the Monte Carlo estimator $S_n^{MC}(J_h(U_h, x_0))$ for the HF objective as a baseline.

$$
S_n^{MC}(J_h(U_h, x_0)) = \frac{1}{n} \sum_{i=1}^{n} J_h(U_h, x_0^{(i)})
$$

Where $n$ is the number of samples of $x_0$ used in the MC estimate.

The CV estimator $S_{n_{cv}}^{CV}(J_h, J_l)$ is constructed using both the HF and LF objectives, and the
analytical expectation of the LF objective function.

$$
S_{n_{cv}}^{CV}(J_h, J_l) = S_{n_{cv}}^{MC}(J_h(U_h, x_0)) + \alpha (S_{n_{cv}}^{MC}(J_l(U_{hla}, x_0)) - \mathbb{E}[J_l(U_{hla}, x_0)])
$$

Choosing $n_{cv}$ samples of $x_0$ to equal the cost of $S_n^{MC}(J_h(U_h, x_0))$ and reusing the same samples for the HF and LF objectives.
The control variate coefficient $\alpha$ can be calculated analytically using the actual mean and covariance of $x_0$
and the equations in section \ref{lqr_ctrl_stoch}.

$$
\alpha = -\frac{\text{Cov}(J_h(U_h, x_0), J_l(U_{hla}, x_0))}{\text{Var}[J_l(U_{hla}, x_0)]}
$$

Finally, the ACV estimator $S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l)$ is constructed using both the HF and LF objectives but with
a statistical estimate of the expectation of the LF objective function.

$$
S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l) = S_{n_{acv}}^{MC}(J_h(U_h, x_0)) + \alpha (S_{n_{acv}}^{MC}(J_l(U_{hla}, x_0)) - S_{m_{acv}}^{MC}(J_l(U_{hla}, x_0)))
$$

Choosing $n_{acv} + m_{acv}$ samples of $x_0$ to equal the cost of $S_n^{MC}(J_h(U_h, x_0))$ and reusing the same samples
for the HF and LF objectives in the first two terms. The coefficient $\alpha$ can be calculated statistically with $n_{acv}$ samples of $x_0$.

We expect the CV estimator to have a lower variance than the MC estimator. Howevever, since it is not possible
to have an analytical expression for the expected value of most objective functions used for trajectory optimization,
especially with constraints, the CV estimator is not always possible to construct. The ACV estimator is a compromise
that converges to the variance of the CV estimator as $m_{acv} \rightarrow \infty$.

\subsection{Numerical optimization}

To optimize trajectory using LQR, to obtain the optimal control inputs $U_h^*$ under stochastic initial conditions $x_0$,
we need to minimize the expected value of the objective function $\mathbb{E}[J_h(U_h, x_0)]$. We do this using off-the-shelf
numerical optimization algorithms present in MATLAB, such as fmincon, fminunc, etc. An important point to consider
is that the variance of the objective function estimation depends on the number of samples of $x_0$ used as well as
the correlation between the HF and LF objectives. We exploit the fact that as the numerical optimizer iterates, it computes
$U_h$ at every iteration and for us to achieve the maximum correlation between the HF and LF objectives, we can use
choose a $U_h$ which when downsampled to $U_l$ gives us the highest corelation $\rho(J_h(U_h, x_0), J_l(U_{hla}, x_0))$.
Hence, at each iteration of the CV/ACV estimators we use the $U_h$ at the current iteration while we use $U_{hla}$ from
the iteration with the highest correlation. This $U_{hla}$ at the iteration with the highest correlation is
$U_{hla}^{max}$. The LF objective is then calculated using this $U_{hla}^{max}$ to be used in the CV/ACV estimators to get the maximum variance reduction.

For numerical optimization using the CV estimator, we save the $U_{hla}^{(k)}$ for every iteration $k$ in an array
so that they can be used to calculate the correlation in all future iterations.

\begin{algorithm}
  \caption{Numerical optimization with CV estimator}
  \begin{algorithmic}
    \Require $J_h, J_l, n_{cv}, U_0, x_0 \mu, \Sigma, k_{max}$
    \State $k \gets 0$ (iteration counter)
    \State $U \gets U_0$ initialize the numerical optimizer
    \While{numerical optimizer has not converged $\wedge$ $k < k_{max}$}
    \State $U_h \gets$ $U$ from the numerical optimizer
    \State $U_{hla}^{(k)} \gets T_{hla} U_h$
    \State $U_{hla}^{max} \gets \underset{U_{hla}(j)} \max \{\rho(J_h(U_h, x_0), J_l(U_{hla}^{(j)}, x_0))\}_{j=1}^k$
    \State $\text{Cov}_{hl} \gets \text{Cov}(J_h(U_h, x_0), J_l(U_{hla}^{max}, x_0))$ calculated analytically using $\mu, \Sigma$
    \State $\text{Var}_l \gets \text{Var}[J_l(U_{hla}^{max}, x_0)]$ calculated analytically using $\mu, \Sigma$
    \State $\alpha \gets -\frac{\text{Cov}_{hl}}{\text{Var}_l}$
    \State $\mathbb{E}[J_l(U_{hla}^{max}, x_0)] \gets$ calculated analytically using $\mu, \Sigma$
    \State $S_{n_{cv}}^{CV}(J_h, J_l) \gets S_{n_{cv}}^{MC}(J_h(U_h, x_0)) + \alpha (S_{n_{cv}}^{MC}(J_l(U_{hla}^{max}, x_0)) - \mathbb{E}[J_l(U_{hla}^{max}, x_0)])$
    \State $k \gets k + 1$
    \State $S_{n_{cv}}^{CV}(J_h, J_l)$ is passed to the numerical optimizer for computing gradients for the next iteration
    \EndWhile
  \end{algorithmic}
\end{algorithm}

Numerical optimization using ACV is similar to CV, but all the terms are calculated statistically using $n_{acv}$ and separate
$m_{acv}$ samples of $x_0$.

\begin{algorithm}
  \caption{Numerical optimization with ACV estimator}
  \begin{algorithmic}
    \Require $J_h, J_l, n_{acv}, m_{acv}, U_0, x_0, k_{max}$
    \State $k \gets 0$ (iteration counter)
    \State $U \gets U_0$ initialize the numerical optimizer
    \While{numerical optimizer has not converged $\wedge$ $k < k_{max}$}
    \State $U_h \gets$ $U$ from the numerical optimizer
    \State $U_{hla}^{(k)} \gets T_{hla} U_h$
    \State $U_{hla}^{max} \gets \underset{U_{hla}(j)} \max \{\rho(J_h(U_h, x_0), J_l(U_{hla}^{(j)}, x_0))\}_{j=1}^k$
    \State $\text{Cov}_{hl} \gets \text{Cov}(J_h(U_h, x_0), J_l(U_{hla}^{max}, x_0))$ calculated statistically using $n_{acv}$ samples
    \State $\text{Var}_l \gets \text{Var}[J_l(U_{hla}^{max}, x_0)]$ calculated statistically using $n_{acv}$ samples
    \State $\alpha \gets -\frac{m_{acv}}{m_{acv} + n_{acv}} \frac{\text{Cov}_{hl}}{\text{Var}_l}$ calculated statistically using $n_{acv}$ samples
    \State $S_{m_{acv}}^{MC}(J_l(U_{hla}^{max}, x_0)) \gets \frac{1}{m_{acv}} \sum_{i=n_{acv}}^{n_{acv}+m_{acv}} J_l(U_{hla}^{max}, x_0^{(i)})$
    \State $S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l) \gets S_{n_{acv}}^{MC}(J_h(U_h, x_0)) + \alpha (S_{n_{acv}}^{MC}(J_l(U_{hla}^{max}, x_0)) - S_{m_{acv}}^{MC}(J_l(U_{hla}^{max}, x_0)))$
    \State $k \gets k + 1$
    \State $S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l)$ is passed to the numerical optimizer for computing gradients for the next iteration
    \EndWhile
  \end{algorithmic}
\end{algorithm}

\section{Extra}
To test the estimators, we set up a couple of experiments.

We fixed $\alpha = -1$ for the ACV estimator and increased the ratio $m:n$ for the ACV estimator
to see what the optimal sample allocation is
\begin{algorithm}
  \caption{ACV sample allocation experiment}
  \begin{algorithmic}
    \Require $J_h, J_l, x_0, e_s, ratio_{cost}, MC_{cost}, ratio_{mn}$
    \State $x_{0,samples} \gets \text{generate samples of } x_0 \text{ for all } e_s$
    \For{$r$ in $ratio_{mn}$}
    \State $n_{acv} \gets MC_{cost} / (1 + ratio_{cost} + r * ratio_{cost})$
    \State $m_{acv} \gets r * n_{acv}$
    \For{$x_0^{(i)}$ in $x_{0,samples}$}
    \State $O^{(i)} \gets S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l, x_0^{(i)})$
    \EndFor
    \State $\text{Var}^{(r)} \gets \text{Var}[O]$
    \EndFor
  \end{algorithmic}
\end{algorithm}

$e_s$ is the number of estimator samples

$ratio_{cost}$ is the ratio of the cost of $J_l$ to $J_h$

$MC_{cost}$ is the equivalent cost of the MC estimator

Then we fixed $n$ for the ACV estimator and increased $m$ to see if it converges to the CV estimator variance
\begin{algorithm}
  \caption{ACV convergence experiment}
  \begin{algorithmic}
    \Require $J_h, J_l, x_0, e_s, ratio_{cost}, MC_{cost}, ms_{acv}$
    \State $x_{0,samples} \gets \text{generate samples of } x_0 \text{ for all } e_s$
    \State $n_{cv} \gets MC_{cost} / (1 + ratio_{cost})$
    \State $n_{acv} \gets MC_{cost} / (1 + ratio_{cost})$ (same as CV)
    \For{$m$ in $ms_{acv}$}
    \State $m_{acv} \gets m$
    \For{$x_0^{(i)}$ in $x_{0,samples}$}
    \State $O_{cv}^{(i)} \gets S_{n_{cv}}^{CV}(J_h, J_l, x_0^{(i)})$
    \State $O_{acv}^{(i)} \gets S_{n_{acv},m_{acv}}^{ACV}(J_h, J_l, x_0^{(i)})$
    \EndFor
    \State $\text{Var}_{cv}^{(m)} \gets \text{Var}[O_{cv}]$
    \State $\text{Var}_{acv}^{(m)} \gets \text{Var}[O_{acv}]$
    \State $\text{Var}^{(m)} \gets (\text{Var}_{acv}^{(m)} - \text{Var}_{cv}^{(m)})^2$
    \EndFor
  \end{algorithmic}
\end{algorithm}

\end{document}
