\documentclass{article}
\usepackage[a4paper, total={7in, 8in}]{geometry}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath} % Required for some math elements
\usepackage{hyperref} % Required for hyperlinks
\usepackage{amssymb} % Required for probability symbols
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{MultifidelityTrajectoryOptimization}
\author{goroda }
\date{October 2024}

\begin{document}

\maketitle

\begin{abstract}
  TODO: abstract
\end{abstract}

\section{Introduction}
TODO: introduction
\section{Background}
TODO: background

\section{Problem Formulation}
This secition describes how the state space model of the dynamics is set up, along with the controller design and cost function for the trajectory optimization problem.
\subsection{Mass-Spring-Damper System}
For this paper, a simplified trajectory optimization problem is considered for ease of modelling.
The objective is to solve a reference tracking problem for the position and velocity of a simple mass-spring-damper system.
The mass-spring-damper system has the following parameters:

\begin{itemize}
  \item $m = 5$ g : Mass
  \item $k = 2$ N/m : Spring constant
  \item $c = 0.5$ Ns/m : Damping coefficient
    % \item Initial position: $x_0 = 0$ m
    % \item Initial velocity: $\dot{x}_0 = 0$ m/s
\end{itemize}

Given an external force $F$ and the acceleration of the system $\ddot{x}$,
the dynamics of the system can be written as the equality of forces acting on the mass:

$$
\begin{aligned}
  m\ddot{x} &= F - c\dot{x} - kx \\
  \implies \ddot{x} &= \frac{F}{m} - \frac{c}{m}\dot{x} - \frac{k}{m}x
\end{aligned}
$$

We have the state as $[x \dot{x}]^T$ containing the position and velocity of the mass, both of which are observed.
The control input $u=F$ is applied to the mass, yielding the following state space model:

$$
\begin{aligned}
  \begin{bmatrix}
    \dot{x} \\
    \ddot{x}
  \end{bmatrix} &=
  \begin{bmatrix}
    0 & 1 \\
    -\frac{k}{m}  -\frac{c}{m}
  \end{bmatrix}
  \begin{bmatrix}
    x \\
    \dot{x}
  \end{bmatrix} +
  \begin{bmatrix}
    0 \\
    \frac{1}{m}
  \end{bmatrix} u \\
  y &=
  \begin{bmatrix}
    1 & 0 \\
    0 & 1
  \end{bmatrix}
  \begin{bmatrix}
    x \\
    \dot{x}
  \end{bmatrix}
\end{aligned}
$$

Thus, we have a standard continuous-time LTI system $\dot{x} = A_cx + B_cu$ and $y = C_cx$, where

\begin{equation}
  \begin{aligned}
    A_c &=
    \begin{bmatrix}
      0 & 1 \\
      -\frac{k}{m} & -\frac{c}{m}
    \end{bmatrix} \\
    B_c &=
    \begin{bmatrix}
      0 \\
      \frac{1}{m}
    \end{bmatrix} \\
    C_c &=
    \begin{bmatrix}
      1 & 0 \\
      0 & 1
    \end{bmatrix}
  \end{aligned}
\end{equation}

\subsection{LQR Controller} \label{lqr_ctrl}
The continuous-time system can be converted to discrete time using such that $x_{k+1} = A x_k + B u_k$ and $y_k = C x_k$ for a chosen sampling time $T_s$.
The $A$ and $B$ matrices for the discrete time system are then used to formulate the cost function for the LQR problem.

We set up an LQR controller to track the reference position and velocity of the mass-spring-damper system.
An LQR controller was chosen because it has a quadratic cost function that can be minimized analytically and gives us a
good reference for the trajectory optimization problem.

The LQR controller minimizes the cost function

$$
\min_{u_0, u_1 ... u_{N-1}}J = \sum_{k=0}^{N-1} (e_k^T Q_e e_k + \Delta u_k^T R \Delta u_k)
$$

Where

\begin{itemize}
  \item $\Delta u_0, \Delta u_1 ... \Delta u_{N-1}$ : control inputs at each timestep of the trajectory
  \item $J$ : total cost to be minimized
  \item $N$ : time horizon
  \item $x_k$ : state vector at time step $k$
  \item $u_k$ : control input vector at time step $k$
  \item $\Delta u_k = u_k - u_{k-1}$ : change in control input at time step $k$
  \item $r_k$ : reference output at time step $k$
  \item $e_k = y_k - r_k = Cx - r_k$ : error in the output at time step $k$
  \item $Q_e$ : error cost matrix
  \item $R$ : control cost matrix
\end{itemize}

Note that we can add a terminal penalty using the DARE solution for the LQR problem, but for simplicity we will not consider it here.

To track the error $e_k$, we extend the state vector $x_k$ to include the control input $u_{k-1}$ and the reference output $r_k$.

$$
x_k^{ext} =
\begin{bmatrix}
  x_k \\
  u_{k-1} \\
  r_k
\end{bmatrix}
$$

With the resulting state space model

\begin{equation}
  \begin{aligned}
    x_{k+1}^{ext} &=
    \begin{bmatrix}
      A & B & 0 \\
      0 & \mathbb{I}_{n_u \times n_u} & 0 \\
      0 & 0 & \mathbb{I}_{n_r \times n_r}
    \end{bmatrix}
    \begin{bmatrix}
      x_k \\
      u_{k-1} \\
      r_k
    \end{bmatrix} +
    \begin{bmatrix}
      B \\
      \mathbb{I}_{n_u \times n_u} \\
      0
    \end{bmatrix} \Delta u_k \\
  \end{aligned}
\end{equation}

with

$$
\begin{aligned}
  A^{ext} &=
  \begin{bmatrix}
    A & B & 0 \\
    0 & \mathbb{I}_{n_u \times n_u} & 0 \\
    0 & 0 & \mathbb{I}_{n_r \times n_r}
  \end{bmatrix} \\
  B^{ext} &=
  \begin{bmatrix}
    B \\
    \mathbb{I}_{n_u \times n_u} \\
    0
  \end{bmatrix}
\end{aligned}
$$

Similary, $Qe$ with the extended state $x_k^{ext}$ transforms to $Q$ such that $e_k^T Q_e e_k = x_k^{ext^T} Q x_k^{ext}$.

$$
\begin{aligned}
  e_k^T Q_e e_k &= (y_k - r_k)^T Q_e (y_k - r_k) \\
  &= \left(
    \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
    \end{bmatrix}
    \begin{bmatrix}
      x_k \\
      u_{k-1} \\
      r_k
  \end{bmatrix}\right)^T Q_e
  \left(
    \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
    \end{bmatrix}
    \begin{bmatrix}
      x_k \\
      u_{k-1} \\
      r_k
  \end{bmatrix}\right) \\
  &= x_k^{ext^T}
  \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
  \end{bmatrix}^T Q_e
  \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
  \end{bmatrix} x_k^{ext} \\
\end{aligned}
$$

\begin{equation}
  Q =
  \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
  \end{bmatrix}^T Q_e
  \begin{bmatrix} C & 0 & -\mathbb{I}_{n_r \times n_r}
  \end{bmatrix}
\end{equation}

For simplicity, from now on we refer to $x_k^{ext}$ as $x_k$, $A^{ext}$ as $A$ and $B^{ext}$ as $B$.
The cost function can now be written as

$$
J = \sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k
$$

Using the state transition formula

$$
\begin{aligned}
  x_1 &= A x_0 + B u_0 \\
  x_2 &= A x_1 + B u_1 = A(A x_0 + B u_0) + B u_1 = A^2 x_0 + A B u_0 + B u_1 \\
  \vdots \\
  x_N &= A x_{N-1} + B u_{N-1} = A^{N-1} x_0 + A^{N-2} B u_0 + A^{N-3} B u_1 + \ldots + B u_{N-1} \\
  \implies x_k &= A^k x_0 + \sum_{i=0}^{k-1} A^{k-1-i} B u_i
\end{aligned}
$$

We construct the matrices $X$, $U$, $S$ and $M$ such that $X = SU + Mx_0$.

$$
\begin{aligned}
  X &=
  \begin{bmatrix}
    x_1^{ext} \\
    x_2^{ext} \\
    \vdots \\
    x_N^{ext}
  \end{bmatrix} & \in \mathbb{R}^{Nn_x \times 1} \\
  U &=
  \begin{bmatrix}
    \Delta u_0 \\
    \Delta u_1 \\
    \vdots \\
    \Delta u_{N-1}
  \end{bmatrix} & \in \mathbb{R}^{Nn_u \times 1} \\
  S &=
  \begin{bmatrix}
    B & 0 & \ldots & 0 \\
    AB & B & \ldots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    A^{N-1} B & A^{N-2} B & \ldots & B
  \end{bmatrix} & \in \mathbb{R}^{Nn_x \times Nn_u} \\
  M &=
  \begin{bmatrix}
    A \\
    A^2 \\
    \vdots \\
    A^N
  \end{bmatrix} & \in \mathbb{R}^{Nn_x \times n_x}
\end{aligned}
$$

Similarly, the matrices $\bar{Q}$ and $\bar{R}$ are constructed

$$
\begin{aligned}
  \bar{Q} &=
  \begin{bmatrix}
    Q & 0 & \ldots & 0 \\
    0 & Q & \ldots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \ldots & 0
  \end{bmatrix} \text{with size } Nn_x \times Nn_x \\
  \bar{R} &=
  \begin{bmatrix}
    R & 0 & \ldots & 0 \\
    0 & R & \ldots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \ldots & R
  \end{bmatrix} \text{with size } Nn_u \times Nn_u
\end{aligned}
$$

The cost function can then be written as a quadratic function of the control inputs $U$

\begin{equation}
  \begin{aligned}
    J &= \sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k \\
    % \text{ (extra $x_0$ term because it is not in $X$)} \\
    &= X^T \bar{Q} X + U^T \bar{R} U + x_0^T Q x_0 \\
    &= (S U + M x_0)^T \bar{Q} (S U + M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } (A + B)^T = A^T + B^T \text{ and } (AB)^T = B^T A^T \\
    &= (U^T S^T + x_0^T M^T) \bar{Q} (S U + M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } A(B + C) = AB + AC \\
    &= (U^T S^T + x_0^T M^T) (\bar{Q} S U + \bar{Q} M x_0) + U^T \bar{R} U + x_0^T Q x_0 \\
    &= U^T S^T \bar{Q} S U + U^T S^T \bar{Q} M x_0 + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } \bar{Q} \text{ is symmetric so it doesnt need to be transposed} \\
    &= U^T S^T \bar{Q} S U + (x_0^T M^T \bar{Q} S U)^T + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{note } x_0^T M^T \bar{Q} S U \text{ is a scalar(check its dimensions), so its transpose is itself} \\
    &= U^T S^T \bar{Q} S U + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0 + U^T \bar{R} U + x_0^T Q x_0 \\
    % & \text{combining all quadratic and repeated terms} \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + 2 x_0^T M^T \bar{Q} S U + x_0^T(M^T \bar{Q} M + Q) x_0\\
  \end{aligned}
\end{equation}

Let

$$
\begin{aligned}
  H &= S^T \bar{Q} S + \bar{R} = H^T \\
  &\text{(quadratic multiplication by diagnonal($\bar{Q}$) results in a symmetric, R is symmetric)} \\
  q &= (x_0^T M^T \bar{Q} S)^T = S^T \bar{Q} M x_0 \\
  c &= x_0^T (M^T \bar{Q} M + Q) x_0
\end{aligned}
$$

The cost function can now be written as a quadratic function of the control inputs $U$

$$
J = U^T H U + 2 q^T U + c
$$

Which has a gradient with respect to $U$ as

$$
\frac{\partial J}{\partial U} = 2 H U + 2 q^T
$$

Assuming minimum exists, we can set the gradient to zero to get the optimal control input $U^*$

\begin{equation}
  \begin{aligned}
    \frac{\partial J}{\partial U} &= 2 H U + 2 q^T = 0 \\
    \implies U^* &= -H^{-1} q
  \end{aligned}
\end{equation}

\subsection{Stochastic LQR Controller} \label{stochastic_lqr}

We consider the case where the initial state $x_0$ is stochastic, with mean $\mu$ and covariance $\Sigma$.
Hence, the state vector $X$ is stochastic, since it is propagating the randomness of $x_0$ forward.
The control input vector $U$ is deterministic. The cost function $J$ is now a random variable,
with an expected value $\mathbb{E}[J]$ and variance $Var[J]$.

\subsubsection{Solution of the Stochastic LQR controller}

The expected value of the cost function over all possible realizations of $x_0$ is

\begin{equation}
  \begin{aligned}
    \mathbb{E}[J] &= \mathbb{E}[\sum_{k=0}^{N-1} x_k^T Q x_k + \Delta u_k^T R \Delta u_k] \\
    &= \mathbb{E}[X^T \bar{Q} X + U^T \bar{R} U + x_0^T Q x_0] \\
    &= \mathbb{E}[X^T \bar{Q} X] + \mathbb{E}[U^T \bar{R} U] + \mathbb{E}[x_0^T Q x_0] \\
    &= \mathbb{E}[(S U + M x_0)^T \bar{Q} (S U + M x_0)] + U^T \bar{R} U + \mathbb{E}[x_0^T Q x_0] \\
    &= \mathbb{E}[U^T S^T \bar{Q} S U + U^T S^T \bar{Q} M x_0 + x_0^T M^T \bar{Q} S U + x_0^T M^T \bar{Q} M x_0] + U^T \bar{R} U + \mathbb{E}[x_0^T] Q \mathbb{E}[x_0] + \text{tr}(Q \text{Cov}[x_0]) \\
    &= U^T S^T \bar{Q} S U + \mathbb{E}[U^T S^T \bar{Q} M x_0] + \mathbb{E}[x_0^T M^T \bar{Q} S U] + \mathbb{E}[x_0^T M^T \bar{Q} M x_0] + U^T \bar{R} U + \mathbb{E}[x_0^T] Q \mathbb{E}[x_0] + \text{tr}(Q \text{Cov}[x_0]) \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + U^T S^T \bar{Q} M \mathbb{E}[x_0] + \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T M^T \bar{Q} M x_0] + \mathbb{E}[x_0^T] Q \mathbb{E}[x_0] + \text{tr}(Q \text{Cov}[x_0]) \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T] M^T \bar{Q} M \mathbb{E}[x_0] + \text{tr}(M^T \bar{Q} M \text{Cov}[x_0]) \dots \\
    & \quad + \mathbb{E}[x_0^T] Q \mathbb{E}[x_0] + \text{tr}(Q \text{Cov}[x_0]) \\
    &= U^T (S^T \bar{Q} S + \bar{R}) U + 2 \mathbb{E}[x_0^T] M^T \bar{Q} S U + \mathbb{E}[x_0^T] (M^T \bar{Q} M + Q) \mathbb{E}[x_0] + \text{tr}((M^T \bar{Q} M + Q) \text{Cov}[x_0]) \\
  \end{aligned}
\end{equation}

Let

$$
\begin{aligned}
  H &= S^T \bar{Q} S + \bar{R} = H^T \\
  q &= (\mathbb{E}[x_0^T] M^T \bar{Q} S)^T = S^T \bar{Q} M \mathbb{E}[x_0] \\
  c &= \mathbb{E}[x_0^T] (M^T \bar{Q} M + Q) \mathbb{E}[x_0] + \text{tr}((M^T \bar{Q} M + Q) \text{Cov}[x_0])
\end{aligned}
$$

The expectation of cost function can be written as

$$
\mathbb{E}[J] = U^T H U + 2 q^T U + c
$$

Which has a gradient with respect to $U$ as

$$
\frac{\partial \mathbb{E}[J]}{\partial U} = 2 H U + 2 q^T
$$

Assuming minimum exists, we can set the gradient to zero to get the optimal control input $U^*$ that minimizes the expected value of the cost function

\begin{equation}
  \begin{aligned}
    \frac{\partial \mathbb{E}[J]}{\partial U} &= 2 H U + 2 q^T = 0 \\
    \implies U^* &= -H^{-1} q
  \end{aligned}
\end{equation}

\subsubsection{Variance and Covariance of cost function in terms of initial state}

% ref for quadratic form: https://en.wikipedia.org/wiki/Quadratic_form_(statistics)
% ref:
% - https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf
% - https://math.stackexchange.com/questions/2163694/expectation-of-quartic-form-for-multivariate-gaussian/4247240#4247240
% - https://math.stackexchange.com/questions/1302882/variance-of-a-quadratic-form

The expected value of the cost function can be rewritten as

$$
\mathbb{E}[J] = K + \mathbb{E}[x_0^T] L + \mathbb{E}[x_0^T] N \mathbb{E}[x_0] + \text{tr}(N \text{Cov}[x_0]) \\
$$

Where

$$
\begin{aligned}
  x_0 &\sim \mathcal{N}(\mu, \Sigma) \\
  K &= U^T(S^T \bar{Q} S + \bar{R}) U \\
  L &= 2 M^T \bar{Q} S U \\
  N &= M^T \bar{Q} M + Q = N^T \\
  &\text{(quadratic multiplication by diagnonal($\bar{Q}$) results in a symmetric, $Q$ is symmetric)} \\
\end{aligned}
$$

Using this, the variance can be calculated.

\begin{equation}
  \begin{aligned}
    Var[J] &= Var[K + x_0^T L + x_0^T N x_0] \\
    &\text{note: $K$ is deterministic, so its variance is 0} \\
    & \text{note: $x_0^T L$ is a scalar, $x_0^T L = L^T x_0$} \\
    &= Var[L^T x_0 + x_0^T N x_0] \\
    &= 2\text{tr}(N \text{Cov}[x_0] N \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N\text{Cov}[x_0]N\mathbb{E}[x_0] + 4 L^T \text{Cov}[x_0] N \mathbb{E}[x_0] + L^T \text{Cov}[x_0] L \\
  \end{aligned}
\end{equation}

To determine the covariance between the costs of two solutions $U_1$ and $U_2$, in different cost functions
$J_1$ and $J_2$, we need to first rewrite the cost functions to differentiate between them.

For $U_1$, the cost function is

$$
\begin{aligned}
  J_1(U_1) &= K_1 + x_0^T L_1 + x_0^T N_1 x_0 \\
  \text{where} \\
  K_1 &= U_1^T(S_1^T \bar{Q}_1 S_1 + \bar{R}_1) U_1 \\
  L_1 &= 2 M_1^T \bar{Q}_1 S_1 U_1 \\
  N_1 &= M_1^T \bar{Q}_1 M + Q_1 \\
  \text{and} \\
  & S_1, M_1, \bar{Q}_1, \bar{R}_1, Q_1 \text{ depend on the discrectization timestep of } J_1
\end{aligned}
$$

Similarly, for $U_2$, the cost function is

$$
\begin{aligned}
  J_2(U_2) &= K_2 + x_0^T L_2 + x_0^T N_2 x_0 \\
  \text{where} \\
  K_2 &= U_2^T(S_2^T \bar{Q}_2 S_2 + \bar{R}_2) U_2 \\
  L_2 &= 2 M_2^T \bar{Q}_2 S_2 U_2 \\
  N_2 &= M_2^T \bar{Q}_2 M + Q_2 \\
  \text{and} \\
  & S_2, M_2, \bar{Q}_2, \bar{R}_2, Q_2 \text{ depend on the discrectization timestep of } J_2
\end{aligned}
$$

% ref:
% - https://math.stackexchange.com/questions/1302882/variance-of-a-quadratic-form
% - https://stats.stackexchange.com/questions/303466/prove-that-mathrmcovxtax-xtbx-2-mathrmtra-sigma-b-sigma-4-mu
% - https://stats.stackexchange.com/questions/35084/covariance-of-a-linear-and-quadratic-form-of-a-multivariate-normal
the covariance between their costs can be calculated as

\begin{equation}\label{eq:covariance}
  \begin{aligned}
    \text{Cov}[J_1(U_1), J_2(U_2)] &= \text{Cov}[K_1 + x_0^T L_1 + x_0^T N_1 x_0, K_2 + x_0^T L_2 + x_0^T N_2 x_0] \\
    &= \text{Cov}[x_0^T L_1 + x_0^T N_1 x_0, x_0^T L_2 + x_0^T N_2 x_0] \text{ (covariance is shift invariant)} \\
    &= \text{Cov}[x_0^T L_1, x_0^T L_2] + \text{Cov}[x_0^T L_1, x_0^T N_2 x_0] + \text{Cov}[x_0^T N_1 x_0, x_0^T L_2] + \text{Cov}[x_0^T N_1 x_0, x_0^T N_2 x_0] \\
  \end{aligned}
\end{equation}

Determining the covariance of each component in equation \ref{eq:covariance},

$$
\begin{aligned}
  \text{Cov}[x_0^T L_1, x_0^T L_2] &= \text{Cov}[L_1^T x_0, L_2^T x_0] \text{ transpose of a scalar is itself} \\
  &= L_1^T \text{Cov}[x_0] L_2 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P74, 3.2d.9
\begin{aligned}
  \text{Cov}[x_0^T L_1, x_0^T N_2 x_0] &= \text{Cov}[x_0^T N_2 x_0, L_1^T x_0] \text{ transpose of a scalar is itself} \\
  &= 2 \mathbb{E}[x_0^T] N_2 \text{Cov}[x_0] L_1 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P74, 3.2d.9
\begin{aligned}
  \text{Cov}[x_0^T N_1 x_0, x_0^T L_2] &= \text{Cov}[x_0^T N_1 x_0, L_2^T x_0] \text{ transpose of a scalar is itself} \\
  &= 2 \mathbb{E}[x_0^T] N_1 \text{Cov}[x_0] L_2 \\
\end{aligned}
$$

$$
% - https://www.researchgate.net/publication/243770190_Quadratic_Forms_in_Random_Variables P75, 3.2d.12
\begin{aligned}
  \text{Cov}[x_0^T N_1 x_0, x_0^T N_2 x_0] &= 2 \text{tr}(N_1 \text{Cov}[x_0] N_2 \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N_1\text{Cov}[x_0]N_2\mathbb{E}[x_0] \\
\end{aligned}
$$

Combining these, we get the covariance as

\begin{equation}
  \begin{aligned}
    \text{Cov}[J_1(U_1), J_2(U_2)] &= L_1^T \text{Cov}[x_0] L_2 + 2 \mathbb{E}[x_0^T] N_2 \text{Cov}[x_0] L_1 + 2 \mathbb{E}[x_0^T] N_1 \text{Cov}[x_0] L_2 \hdots \\
    & \quad + 2 \text{tr}(N_1 \text{Cov}[x_0] N_2 \text{Cov}[x_0]) + 4 \mathbb{E}[x_0^T]N_1\text{Cov}[x_0]N_2\mathbb{E}[x_0]
  \end{aligned}
\end{equation}

\section{Monte Carlo with Control Variates}
TODO: explain why we need control variates

This section formulates the stochastic trajectory optimization problem as a Monte Carlo problem with a low fidelity control variate.

\subsection{Comparing optimums of high and low fidelity models} \label{comp_opt}

To determine if the low fidelity model can be used as a control variate, we need to determine if it correlates with the high fidelity model.

System Setup:
\begin{itemize}
  \item $J_h(u, x_0)$: High fidelity model/cost function
  \item $J_l(u, x_0)$: Low fidelity model/cost function
  \item $u_h$: Control input in high fidelity model, $n_{u_h} \times 1$
  \item $u_l$: Control input in low fidelity model, $n_{u_l} \times 1$
  \item $x_0$: Random initial state
  \item $u_h^*$: High fidelity optimum
  \item $u_l^*$: Low fidelity optimum
\end{itemize}

$u_h$ and $u_l$ do not have the same dimensions, so to compare them we need to scale them to the same dimensions.

To upsample $u_l \rightarrow u_h$, we repeat the elements of $u_l$ to match the dimensions of $u_h$.
This can be seen as multiplying $u_l$ with a matrix $T_{lh}$ of size $n_{u_h} \times n_{u_l}$:

\begin{equation}
  T_{lh} =
  \begin{bmatrix}
    1 & 0 & \ldots & 0 \\
    1 & 0 & \ldots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 1 & \ldots & 0 \\
    0 & 1 & \ldots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \ldots & 1 \\
    0 & 0 & \ldots & 1 \\
    \vdots & \vdots & \ddots & \vdots \\
  \end{bmatrix}
\end{equation}

where the number of repeating ones in each column is determined by the ratio $r_{hl} = n_{u_h} / n_{u_l}$.
This gives us $u_{lh} = T_{lh} u_l$, which can be compared with $u_h$.

To downsample $u_h \rightarrow u_l$, we can either restrict the dimensions of $u_h$ to match $u_l$ or average the elements of $u_h$ to match the dimensions of $u_l$.

In case of restriction, we can multiply $u_h$ with a matrix $T_{hlr}$ of size $n_{u_l} \times n_{u_h}$:

\begin{equation}
  T_{hlr} =
  \begin{bmatrix}
    1 & 0 & \ldots & 0 & 0 \\
    0 & \ldots & 1 & \ldots & 0 \\
    \vdots & \ddots & \vdots & \ddots & \vdots \\
    0 & 0 & \ldots & 0 & 1 \\
  \end{bmatrix}
\end{equation}

Where the number of columns after which the next one is selected is determined by the ratio $r_{hl} = n_{u_h} / n_{u_l}$.
This gives us $u_{hlr} = T_{hlr} u_h$, which can be compared with $u_l$.

To downsample $u_h$ to $u_l$ by averaging, we need the ratio $r_{lh} = n_{u_h} / n_{u_l}$.
We can then multiply $u_h$ with a matrix $T_{hla}$ of size $n_{u_l} \times n_{u_h}$:

\begin{equation}
  T_{hla} =
  \begin{bmatrix}
    r_{lh} & \ldots & 0 & 0 & 0 \\
    0 & \ldots & r_{lh} & \ldots & 0 \\
    \vdots & \ddots & \vdots & \vdots & \vdots \\
    0 & 0 & 0 & r_{lh} & \ldots \\
  \end{bmatrix}
\end{equation}

Where $r_{lh}$ is repeated $r_{hl}$ times in each row.
This gives us $u_{hla} = T_{hla} u_h$, which can be compared with $u_l$.

\subsection{Correlation between high and low fidelity models}

$u_h$ and $u_l$ each have $n_{u_h}$ and $n_{u_l}$ dimensions respectively, which represent the time steps of the simulation.
After converting them to the same dimensions as done in section \ref{comp_opt},
the cost for some realizations of the initial state $x_0$ can be computed.
Hence, a set of costs of both high and low fidelity control inputs can be computed for a certain model/cost function.
The correlation coefficient $\rho$ can then be computed between the distribution of the cost function values.
To illustrate this, assume there are $N$ realizations of the initial state $x_0$, and $J$ is the cost function.
$u_h$ and $u_l$ are the control inputs for the high and low fidelity models respectively, where the dimensions have been
converted to the same number as described in section \ref{comp_opt}. $\mu_h$ and $\mu_l$ are the mean costs
of the high and low fidelity control inputs respectively, and $\sigma_h$ and $\sigma_l$ are the standard deviations of
the costs of the high and low fidelity control inputs respectively.

\begin{equation}
  \rho(J(u_h), J(u_l)) = \frac{1}{N-1} \sum_{i=1}^{N} \left( \frac{J(u_h, x_0^i) - \mu_h}{\sigma_h} \right) \left( \frac{J(u_l, x_0^i) - \mu_l}{\sigma_l} \right)
\end{equation}

This can be simplified to:

\begin{equation}
  \rho(J(u_h), J(u_l)) = \frac{\text{Cov}(J(u_h), J(u_l))}{\sigma_h \sigma_l}
\end{equation}

This correlation coefficient $\rho$ can be calculated using the MATLAB function \href{https://www.mathworks.com/help/matlab/ref/corrcoef.html#bunkaln}{\texttt{corrcoef}}.

The correlation can also be calculated analytically using the covariance of the costs in the high fidelity objective function and the low fidelity objective function.
Let

\begin{itemize}
  \item $J_h$: high fidelity cost function
  \item $J_l$: low fidelity cost function
  \item $U_1$: high fidelity control input
  \item $U_2$: downsampled high fidelity control input $= T_{hlr} U_1$ or $T_{hla} U_1$
  \item $J_1 = J_h(U_1, x_0)$
  \item $J_2 = J_l(U_2, x_0)$
  \item $\sigma_1$: standard deviation of $J_1$, $=\sqrt{\text{Var}[J_1]}$
  \item $\sigma_2$: standard deviation of $J_2$, $=\sqrt{\text{Var}[J_2]}$
\end{itemize}

Then correlation coefficient between $J_1$ and $J_2$ is

\begin{equation}
  \begin{aligned}
    \rho(J_1, J_2) &= \frac{\text{Cov}(J_1, J_2)}{\sigma_1 \sigma_2} \\
    &= \frac{\text{Cov}(J_1, J_2)}{\sqrt{\text{Var}[J_1]} \sqrt{\text{Var}[J_2]}}
  \end{aligned}
\end{equation}

Where $\text{Cov}(J_1, J_2)$, $\text{Var}[J_1]$ and $\text{Var}[J_2]$ can be calculated using the equations in section \ref{lqr_ctrl}.

\subsection{Correlation Experiments}

We conducted experiments to check the correlation in 2 scenarios:
\begin{itemize}
  \item Perturbation in the direction of steepest ascent
  \item Along the path of a numerical optimizer
\end{itemize}

\subsubsection{Perturbation in the direction of steepest ascent}

Since the solution of the cost function is determined analytically, we cannot use it to determine the direction of steepest ascent.
The gradient at the solution will be 0. To get the direction of steepest ascent, the solution was perturbed slightly in random directions and the direction with the highest gradient
was chosen as the direction of steepest ascent.

\textbf{Perturbation in the high fidelity model/cost function}

When perturbing in the high fidelity model/cost function, the perturbed high fidelity solution was downsampled to low fidelity
dimensions by either restricting or averaging as described in section \ref{comp_opt}.

Hence, we have the following important variables:

\begin{itemize}
  \item $J_h$: High fidelity model/cost function
  \item $J_l$: Low fidelity model/cost function
  \item $u_h^*$: High fidelity optimum
  \item $p_h$: High fidelity perturbation
  \item $u_h = u_h^* + p_h$: Perturbed high fidelity solution
  \item $u_{hlr} = T_{hlr} u_h$: Perturbed high fidelity solution downsampled using restriction:
  \item $u_{hla} = T_{hla} u_h$: Perturbed high fidelity solution downsampled using averaging
\end{itemize}

Comparing $J_h(u_h, x_0)$ and $J_l(u_{hlr}, x_0)$

Comparing $J_h(u_h, x_0)$ and $J_l(u_{hla}, x_0)$

\textbf{Perturbation in the low fidelity model/cost function}

When perturbing in the low fidelity model/cost function, the perturbed high fidelity solution was determined
by converting the low fidelity perturbation to high fidelity dimensions as described in section \ref{comp_opt}.

Hence, we have the following important variables:

\begin{itemize}
  \item $J_h$: High fidelity model/cost function
  \item $J_l$: Low fidelity model/cost function
  \item $u_l^*$: Low fidelity optimum
  \item $p_l$: Low fidelity perturbation
  \item $u_l = u_l^* + p_l$: Perturbed low fidelity solution
  \item $u_{lh} = T_{lh} u_l$: Perturbed high fidelity solution upsampled
\end{itemize}

Comparing $J_h(u_{lh}, x_0)$ and $J_l(u_l, x_0)$

\subsubsection{Along the path of a numerical optimizer}

Since in a realistic scenario, one would be optimizing using a numerical optimizer, and desire to reach the high fidelity optimum,
we conducted experiments to check the correlation along the path of a numerical optimizer in the high fidelity model/cost function.

Here, we warm start with the low fidelity optimum, and check the correlation by downsampling the high fidelity solution using averaging.

Hence, we have the following important variables:

\begin{itemize}
  \item $J_h$: High fidelity model/cost function
  \item $J_l$: Low fidelity model/cost function
  \item $u_h$: High fidelity solution
  \item $u_{hlr} = T_{hlr} u_h$: High fidelity solution downsampled using restriction
  \item $u_{hla} = T_{hla} u_h$: High fidelity solution downsampled using averaging
\end{itemize}

Comparing $J_h(u_h, x_0)$ and $J_h(u_{hlr}, x_0)$

Comparing $J_h(u_h, x_0)$ and $J_l(u_{hla}, x_0)$

It is also possible to compute the correlation between $J_h(u_h, x_0)$ and $J_l(u_{hlr}, x_0)$ for every iteration of the numerical optimizer.
This helps us determine if there is a certain iteration of $J_l(u_{hlr}, x_0)$ that correlates well with all iterations of $J_h(u_h, x_0)$.
The same comparison can be made with $J_l(u_{hla}, x_0)$.

Comparing correlation between $J_h(u_h, x_0)$ and $J_h(u_{hlr}, x_0)$ across all iterations

Comparing correlation between $J_h(u_h, x_0)$ and $J_l(u_{hla}, x_0)$ across all iterations

\subsection{Control Variate Construction}

The control variate is constructed using the low fidelity model/cost function, since we have found that there is some correlation between $J_h(u_h, x_0)$ and $J_l(u_{hla}, x_0)$.
Here we are only using the averaged downsampled high fidelity solution $u_{hla}$ as the control variate.
The important variables for constructing the control variate are:

\begin{itemize}
  \item $x_0$: Random initial state
  \item $J_h$: High fidelity model/cost function
  \item $J_l$: Low fidelity model/cost function
  \item $u_h$: High fidelity solution
  \item $u_{hla} = T_{hla} u_h$: High fidelity solution downsampled using averaging
  \item $S_n^{MC}(J_h(u_h, x_0))$: Monte Carlo estimate of the high fidelity cost function
  \item $S_n^{MC}(J_l(u_{hla}, x_0))$: Monte Carlo estimate of the low fidelity cost function
  \item $\alpha$: Control variate coefficient
\end{itemize}

The control variate coefficient $\alpha$ can be calculated as

\begin{equation}
  \alpha = -\frac{\text{Cov}(J_h(u_h, x_0), J_l(u_{hla}, x_0))}{\text{Var}[J_l(u_{hla}, x_0)]}
\end{equation}

Hence, the control variate is

\begin{equation}
  S_n^{CV}(J_h, J_l) = S_n^{MC}(J_h(u_h, x_0)) + \alpha (S_n^{MC}(J_l(u_{hla}, x_0)) - \mathbb{E}[J_l(u_{hla}, x_0)])
\end{equation}

Where the samples of $x_0$ used in $J_h(u_h, x_0)$ and $J_l(u_{hla}, x_0)$ are the same.

Note that $\text{Cov}(J_h(u_h, x_0), J_l(u_{hla}, x_0))$, $\text{Var}[J_l(u_{hla}, x_0)]$ and $\mathbb{E}[J_l(u_{hla}, x_0)]$ are calculated analytically using the equations in section \ref{stochastic_lqr}.

\subsection{Numerical optimizer using Control Variate}

The numerical optimizer was run in 3 different scenarios

\begin{itemize}
  \item $S_n^{MC}(J_h(U_h, x_0))$: MC estimate of the high fidelity cost function
  \item $S_n^{CV}(J_h(U_h, x_0), J_l(U_{hla}, x_0))$: CV estimate with $u_{hla}$ at the current iteration
  \item $S_n^{CV_{max}}(J_h(U_h, x_0), J_l(U_{hla}^{max}, x_0))$:CV estimate where $u_{hla}^{max}$ is at the iteration with the highest correlation.
\end{itemize}

This is how the whole routine works, step-by-step:

Initialization:
\begin{itemize}
  \item $U_l^* \gets$ Analytical solution of low fidelity model
  \item $U_{h_0} \gets T_{lh} U_l^*$
\end{itemize}

% For $S_n^{CV}$ the numerical optimizer is run for $i^{max}$ iterations, where in each iteration $i$, the objective is calculated:
% \begin{equation}
%   S_n^{CV}(J_h, J_l) = S_n^{MC}(J_h(U, x_0)) + \alpha (S_n^{MC}(J_l(U_{hla}, x_0)) - \mathbb{E}[J_l(U_{hla}, x_0)])
% \end{equation}

% Where
% \begin{itemize}
%   \item $n$: Number of samples of $x_0$ used in the MC estimate to equal the cost of $S^{MC}(J_h(U, x_0))$ with all samples
%   \item $U_{hla} = T_{hla} U$
%   \item $\alpha = -\frac{\text{Cov}(J_h(U, x_0), J_l(U_{hla}, x_0))}{\text{Var}[J_l(U_{hla}, x_0)]}$ is calculated analytically
%   \item $\mathbb{E}[J_l(U_{hla}, x_0)]$ is calculated analytically
% \end{itemize}

% For $S_n^{CV_{max}}$ the numerical optimizer is run for $i^{max}$ iterations, where in each iteration $i$, the objective is calculated:
% \begin{equation}
%   S_n^{CV_{max}}(J_h, J_l) = S_n^{MC}(J_h(U, x_0)) + \alpha (S_n^{MC}(J_l(U_{hla}^{max}, x_0)) - \mathbb{E}[J_l(U_{hla}^{max}, x_0)])
% \end{equation}

% Where
% \begin{itemize}
%   \item $n$: Number of samples of $x_0$ used in the MC estimate to equal the cost of $S^{MC}(J_h(U, x_0))$ with all samples
%   \item $U_{hla} = T_{hla} U$
%   \item $U_{hla}^{max} = \underset{U_{hla}(j)}{max} \{\rho(J_h(U(i), x_0^n), J_l(U_{hla}(j), x_0^n))\}_{j=1}^i$
%   \item $\alpha = -\frac{\text{Cov}(J_h(U, x_0), J_l(U_{hla}^{max}, x_0))}{\text{Var}[J_l(U_{hla}^{max}, x_0)]}$ is calculated analytically
%   \item $\mathbb{E}[J_l(U_{hla}^{max}, x_0)]$ is calculated analytically
% \end{itemize}

For $S_{nm}^{ACV}$ the numerical optimizer is run for $i^{max}$ iterations, where in each iteration $i$, the objective is calculated:
\begin{equation}
  S_{nm}^{ACV}(J_h, J_l) = S_n^{MC}(J_h(U, x_0)) + \alpha (S_n^{MC}(J_l(U_{hla}, x_0)) - S_m^{MC}(J_l(U_{hla}, x_0)))
\end{equation}

Where
\begin{itemize}
  \item $m$: Total number of samples of $x_0$
  \item $n$: Number of samples of $x_0$ used in the MC estimate to equal the cost of $S_m^{MC}(J_h(U, x_0))$ (without considering the cost of $S_m^{MC}(J_l(U_{hla}, x_0))$)
  \item $U_{hla} = T_{hla} U$
  \item $\alpha = -\frac{\text{Cov}(J_h(U, x_0^n), J_l(U_{hla}, x_0^n))}{\text{Var}[J_l(U_{hla}, x_0^n)]}$ is calculated statistically with $n$ samples
\end{itemize}

For $S_{nm}^{ACV_{max}}$ the numerical optimizer is run for $i^{max}$ iterations, where in each iteration $i$, the objective is calculated:
\begin{equation}
  S_{nm}^{ACV_{max}}(J_h, J_l) = S_n^{MC}(J_h(U, x_0)) + \alpha (S_n^{MC}(J_l(U_{hla}^{max}, x_0)) - S_m^{MC}(J_l(U_{hla}^{max}, x_0)))
\end{equation}

Where
\begin{itemize}
  \item $m$: Total number of samples of $x_0$
  \item $n$: Number of samples of $x_0$ used in the MC estimate to equal the cost of $S_m^{MC}(J_h(U, x_0))$ (without considering the cost of $S_m^{MC}(J_l(U_{hla}, x_0))$)
  \item $U_{hla} = T_{hla} U$
  \item $U_{hla}^{max} = \underset{U_{hla}(j)}{max} \{\rho(J_h(U(i), x_0^n), J_l(U_{hla}(j), x_0^n))\}_{j=1}^i$
  \item $\alpha = -\frac{\text{Cov}(J_h(U, x_0^n), J_l(U_{hla}^{max}, x_0^n))}{\text{Var}[J_l(U_{hla}^{max}, x_0^n)]}$ is calculated statistically with $n$ samples
\end{itemize}

For these experiments, $n$, the number of samples of $x_0$ used in the MC estimate, was compared between 10, 100, 500 and 1000.
The comparison is done between $S_n^{MC}(J_h(u_h, x_0))$ vs $S_{\frac{n}{2}}^{CV}(J_h, J_l)$ and $S_{\frac{n}{2}}^{CV_{max}}(J_h, J_l)$ to keep the number of cost function evaluations the same with the control variate estimators having a lower computational cost due to half the sammples being used in the low fidelity cost function.

To compare the variance, we ran a numerical optimizer with n random samples of $x_0$ and calculated the variance for each iteration.

The variance was also calculated analytically for each control variate
\end{document}
